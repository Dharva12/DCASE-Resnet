{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharva12/DCASE-Resnet/blob/main/DCASE_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBlqsNLjQQnf",
        "outputId": "9c40b0ab-d8e7-491c-8dee-8cdf146d1519"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w1eayXfvQOTR"
      },
      "outputs": [],
      "source": [
        "# select a GPU\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to script DCASE2019_network.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UkBrcYXgRfJV",
        "outputId": "bac86c9b-fa58-4e76-fd7e-04345c1bc9ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'DCASE2019_network.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to script DCASE_training_functions.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZwYZfGJeRqa6",
        "outputId": "92a6654a-e0bd-48cb-866d-17f3284177d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'DCASE_training_functions.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import DCASE2019_network\n"
      ],
      "metadata": {
        "id": "InWZ92gLR7Ye"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from DCASE2019_network import model_resnet\n",
        "from DCASE_training_functions import LR_WarmRestart, MixupGenerator"
      ],
      "metadata": {
        "id": "JSrlkAQTR8JB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFZ0UyQwQOTS",
        "outputId": "90348e81-39ae-4433-8873-718557abd139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librosa version =  0.10.2\n",
            "Pysoundfile version =  0.12.1\n",
            "keras version =  2.15.0\n",
            "tensorflow version =  2.15.0\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import soundfile as sound\n",
        "\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "print(\"Librosa version = \",librosa.__version__)\n",
        "print(\"Pysoundfile version = \",sound.__version__)\n",
        "print(\"keras version = \",keras.__version__)\n",
        "print(\"tensorflow version = \",tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Y1-MlJc4QOTS"
      },
      "outputs": [],
      "source": [
        "WhichTask = '1a'\n",
        "#WhichTask = '1b'\n",
        "#WhichTask = '1c'\n",
        "\n",
        "if WhichTask =='1a':\n",
        "    ThisPath = '/content/drive/MyDrive/dataset_root/TAU-urban-acoustic-scenes-2019-development_(Subtask A)/audio /'\n",
        "    TrainFile = '/content/drive/MyDrive/dataset_root/TAU-urban-acoustic-scenes-2019-development_(Subtask A)/evaluation_setup/fold1_train.csv'\n",
        "    ValFile = '/content/drive/MyDrive/dataset_root/TAU-urban-acoustic-scenes-2019-development_(Subtask A)/evaluation_setup/fold1_evaluate.csv'\n",
        "    sr = 48000\n",
        "    num_audio_channels = 2\n",
        "elif WhichTask =='1b':\n",
        "    ThisPath = '../Task1b/'\n",
        "    TrainFile = ThisPath + 'evaluation_setup/fold1_train.csv'\n",
        "    ValFile = ThisPath + 'evaluation_setup/fold1_evaluate.csv'\n",
        "    sr = 44100\n",
        "    num_audio_channels = 1\n",
        "elif WhichTask =='1c':\n",
        "    ThisPath = '../Task1c/'\n",
        "    TrainFile = ThisPath + 'evaluation_setup/fold1_train.csv'\n",
        "    sr = 44100\n",
        "    num_audio_channels = 1\n",
        "\n",
        "SampleDuration = 10\n",
        "\n",
        "#log-mel spectrogram parameters\n",
        "NumFreqBins = 128\n",
        "NumFFTPoints = 2048\n",
        "HopLength = int(NumFFTPoints/2)\n",
        "NumTimeBins = int(np.ceil(SampleDuration*sr/HopLength))\n",
        "\n",
        "#training parameters\n",
        "max_lr = 0.1\n",
        "batch_size = 32\n",
        "num_epochs = 510\n",
        "mixup_alpha = 0.4\n",
        "crop_length = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kOhSwgf-QOTT"
      },
      "outputs": [],
      "source": [
        "#load filenames and labels\n",
        "dev_train_df = pd.read_csv(TrainFile, sep=',', encoding='ASCII')\n",
        "dev_val_df = pd.read_csv(ValFile, sep=',', encoding='ASCII')\n",
        "wavpaths_train = dev_train_df['filename'].tolist()\n",
        "wavpaths_val = dev_val_df['filename'].tolist()\n",
        "y_train_labels =  dev_train_df['scene_label'].astype('category').cat.codes.values\n",
        "y_val_labels =  dev_val_df['scene_label'].astype('category').cat.codes.values\n",
        "\n",
        "ClassNames = np.unique(dev_train_df['scene_label'])\n",
        "NumClasses = len(ClassNames)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train_labels, NumClasses)\n",
        "y_val = keras.utils.to_categorical(y_val_labels, NumClasses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "unique_rows = np.unique(y_val, axis=0)\n",
        "\n",
        "# Print the unique rows\n",
        "print(unique_rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8Jan_75UcWhN",
        "outputId": "ceb68627-61ca-4fc1-ed3e-3d100aac7a57"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load wav files and get log-mel spectrograms, deltas, and delta-deltas\n",
        "def deltas(X_in):\n",
        "    X_out = (X_in[:,:,2:,:]-X_in[:,:,:-2,:])/10.0\n",
        "    X_out = X_out[:,:,1:-1,:]+(X_in[:,:,4:,:]-X_in[:,:,:-4,:])/5.0\n",
        "    return X_out\n",
        "\n",
        "LM_train = np.zeros((len(wavpaths_train),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
        "for i in range(len(wavpaths_train)):\n",
        "    stereo,fs = sound.read(ThisPath + wavpaths_train[i],stop=SampleDuration*sr)\n",
        "    for channel in range(num_audio_channels):\n",
        "        if len(stereo.shape)==1:\n",
        "            stereo = np.expand_dims(stereo,-1)\n",
        "        LM_train[i,:,:,channel]= librosa.feature.melspectrogram(y=stereo[:,channel],\n",
        "                                       sr=sr,\n",
        "                                       n_fft=NumFFTPoints,\n",
        "                                       hop_length=HopLength,\n",
        "                                       n_mels=NumFreqBins,\n",
        "                                       fmin=0.0,\n",
        "                                       fmax=sr/2,\n",
        "                                       htk=True,\n",
        "                                       norm=None)\n",
        "\n",
        "LM_train = np.log(LM_train+1e-8)\n",
        "LM_deltas_train = deltas(LM_train)\n",
        "LM_deltas_deltas_train = deltas(LM_deltas_train)\n",
        "LM_train = np.concatenate((LM_train[:,:,4:-4,:],LM_deltas_train[:,:,2:-2,:],LM_deltas_deltas_train),axis=-1)\n",
        "\n",
        "LM_val = np.zeros((len(wavpaths_val),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
        "for i in range(len(wavpaths_val)):\n",
        "    stereo,fs = sound.read(ThisPath + wavpaths_val[i],stop=SampleDuration*sr)\n",
        "    for channel in range(num_audio_channels):\n",
        "        if len(stereo.shape)==1:\n",
        "            stereo = np.expand_dims(stereo,-1)\n",
        "        LM_val[i,:,:,channel]= librosa.feature.melspectrogram(y=stereo[:,channel],\n",
        "                                       sr=sr,\n",
        "                                       n_fft=NumFFTPoints,\n",
        "                                       hop_length=HopLength,\n",
        "                                       n_mels=NumFreqBins,\n",
        "                                       fmin=0.0,\n",
        "                                       fmax=sr/2,\n",
        "                                       htk=True,\n",
        "                                       norm=None)\n",
        "\n",
        "LM_val = np.log(LM_val+1e-8)\n",
        "LM_deltas_val = deltas(LM_val)\n",
        "LM_deltas_deltas_val = deltas(LM_deltas_val)\n",
        "LM_val = np.concatenate((LM_val[:,:,4:-4,:],LM_deltas_val[:,:,2:-2,:],LM_deltas_deltas_val),axis=-1)\n"
      ],
      "metadata": {
        "id": "VlhZeDdf-oee"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_time_bins_train = max(LM_train.shape[2] for LM_train in LM_train)\n",
        "max_time_bins_val = max(LM_val.shape[2] for LM_val in LM_val)\n",
        "\n",
        "print(\"Maximum number of time bins in training data:\", max_time_bins_train)\n",
        "print(\"Maximum number of time bins in validation data:\", max_time_bins_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h12S1WDNJ3ON",
        "outputId": "46d3a1fb-d0e4-4fda-ebb5-c8503848ff4e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum number of time bins in training data: 6\n",
            "Maximum number of time bins in validation data: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create and compile the model\n",
        "model = model_resnet(NumClasses,\n",
        "                     input_shape =[NumFreqBins,None,3*num_audio_channels],\n",
        "                     num_filters =24,\n",
        "                     wd=1e-3)\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Define optimizer with learning_rate instead of lr and remove decay\n",
        "optimizer = SGD(learning_rate=max_lr, momentum=0.9, nesterov=False)\n",
        "\n",
        "# Compile the model using the defined optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpZ-_8p_svkf",
        "outputId": "58951ff1-09c5-4426-aa27-326ff3fa055d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 128, None, 6)]       0         []                            \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)           (None, 64, None, 6)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)           (None, 64, None, 6)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 64, None, 6)          24        ['lambda_8[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 64, None, 6)          24        ['lambda_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 64, None, 24)         1296      ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 64, None, 24)         1296      ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 64, None, 24)         48        ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 64, None, 24)         48        ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 64, None, 24)         5184      ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 64, None, 24)         5184      ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 64, None, 24)         48        ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 64, None, 24)         48        ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 64, None, 24)         5184      ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 64, None, 24)         5184      ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 64, None, 24)         0         ['conv2d_40[0][0]',           \n",
            "                                                                     'conv2d_36[0][0]']           \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 64, None, 24)         0         ['conv2d_41[0][0]',           \n",
            "                                                                     'conv2d_37[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 64, None, 24)         48        ['add_16[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 64, None, 24)         48        ['add_17[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 64, None, 24)         5184      ['activation_38[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 64, None, 24)         5184      ['activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 64, None, 24)         48        ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 64, None, 24)         48        ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 64, None, 24)         5184      ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 64, None, 24)         5184      ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 64, None, 24)         0         ['conv2d_44[0][0]',           \n",
            "                                                                     'add_16[0][0]']              \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 64, None, 24)         0         ['conv2d_45[0][0]',           \n",
            "                                                                     'add_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 64, None, 24)         48        ['add_18[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 64, None, 24)         48        ['add_19[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 64, None, 24)         0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 64, None, 48)         10368     ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 64, None, 48)         10368     ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 64, None, 48)         96        ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (Avera  (None, 64, None, 24)         0         ['add_18[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 64, None, 48)         96        ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (Avera  (None, 64, None, 24)         0         ['add_19[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)          (None, 64, None, 24)         0         ['average_pooling2d_6[0][0]'] \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)          (None, 64, None, 24)         0         ['average_pooling2d_7[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 64, None, 48)         20736     ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 64, None, 48)         0         ['average_pooling2d_6[0][0]', \n",
            " )                                                                   'lambda_10[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 64, None, 48)         20736     ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 64, None, 48)         0         ['average_pooling2d_7[0][0]', \n",
            " )                                                                   'lambda_11[0][0]']           \n",
            "                                                                                                  \n",
            " add_20 (Add)                (None, 64, None, 48)         0         ['conv2d_48[0][0]',           \n",
            "                                                                     'concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " add_21 (Add)                (None, 64, None, 48)         0         ['conv2d_49[0][0]',           \n",
            "                                                                     'concatenate_8[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 64, None, 48)         96        ['add_20[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 64, None, 48)         96        ['add_21[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 64, None, 48)         20736     ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 64, None, 48)         20736     ['activation_47[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 64, None, 48)         96        ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 64, None, 48)         96        ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 64, None, 48)         20736     ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 64, None, 48)         20736     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " add_22 (Add)                (None, 64, None, 48)         0         ['conv2d_52[0][0]',           \n",
            "                                                                     'add_20[0][0]']              \n",
            "                                                                                                  \n",
            " add_23 (Add)                (None, 64, None, 48)         0         ['conv2d_53[0][0]',           \n",
            "                                                                     'add_21[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 64, None, 48)         96        ['add_22[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 64, None, 48)         96        ['add_23[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 64, None, 48)         0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 64, None, 96)         41472     ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 64, None, 96)         41472     ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 64, None, 96)         192       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (Avera  (None, 64, None, 48)         0         ['add_22[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 64, None, 96)         192       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " average_pooling2d_9 (Avera  (None, 64, None, 48)         0         ['add_23[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)          (None, 64, None, 48)         0         ['average_pooling2d_8[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)          (None, 64, None, 48)         0         ['average_pooling2d_9[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 64, None, 96)         82944     ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 64, None, 96)         0         ['average_pooling2d_8[0][0]', \n",
            " )                                                                   'lambda_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 64, None, 96)         82944     ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 64, None, 96)         0         ['average_pooling2d_9[0][0]', \n",
            " e)                                                                  'lambda_13[0][0]']           \n",
            "                                                                                                  \n",
            " add_24 (Add)                (None, 64, None, 96)         0         ['conv2d_56[0][0]',           \n",
            "                                                                     'concatenate_9[0][0]']       \n",
            "                                                                                                  \n",
            " add_25 (Add)                (None, 64, None, 96)         0         ['conv2d_57[0][0]',           \n",
            "                                                                     'concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 64, None, 96)         192       ['add_24[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 64, None, 96)         192       ['add_25[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 64, None, 96)         82944     ['activation_54[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 64, None, 96)         82944     ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 64, None, 96)         192       ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 64, None, 96)         192       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 64, None, 96)         82944     ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 64, None, 96)         82944     ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " add_26 (Add)                (None, 64, None, 96)         0         ['conv2d_60[0][0]',           \n",
            "                                                                     'add_24[0][0]']              \n",
            "                                                                                                  \n",
            " add_27 (Add)                (None, 64, None, 96)         0         ['conv2d_61[0][0]',           \n",
            "                                                                     'add_25[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 64, None, 96)         192       ['add_26[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 64, None, 96)         192       ['add_27[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 64, None, 96)         0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 64, None, 192)        165888    ['activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 64, None, 192)        165888    ['activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 64, None, 192)        384       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " average_pooling2d_10 (Aver  (None, 64, None, 96)         0         ['add_26[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 64, None, 192)        384       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " average_pooling2d_11 (Aver  (None, 64, None, 96)         0         ['add_27[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 64, None, 192)        0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)          (None, 64, None, 96)         0         ['average_pooling2d_10[0][0]']\n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 64, None, 192)        0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)          (None, 64, None, 96)         0         ['average_pooling2d_11[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 64, None, 192)        331776    ['activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 64, None, 192)        0         ['average_pooling2d_10[0][0]',\n",
            " e)                                                                  'lambda_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 64, None, 192)        331776    ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 64, None, 192)        0         ['average_pooling2d_11[0][0]',\n",
            " e)                                                                  'lambda_15[0][0]']           \n",
            "                                                                                                  \n",
            " add_28 (Add)                (None, 64, None, 192)        0         ['conv2d_64[0][0]',           \n",
            "                                                                     'concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " add_29 (Add)                (None, 64, None, 192)        0         ['conv2d_65[0][0]',           \n",
            "                                                                     'concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 64, None, 192)        384       ['add_28[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 64, None, 192)        384       ['add_29[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 64, None, 192)        0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 64, None, 192)        0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 64, None, 192)        331776    ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 64, None, 192)        331776    ['activation_63[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 64, None, 192)        384       ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 64, None, 192)        384       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 64, None, 192)        0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 64, None, 192)        0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 64, None, 192)        331776    ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 64, None, 192)        331776    ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " add_30 (Add)                (None, 64, None, 192)        0         ['conv2d_68[0][0]',           \n",
            "                                                                     'add_28[0][0]']              \n",
            "                                                                                                  \n",
            " add_31 (Add)                (None, 64, None, 192)        0         ['conv2d_69[0][0]',           \n",
            "                                                                     'add_29[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 128, None, 192)       0         ['add_30[0][0]',              \n",
            " e)                                                                  'add_31[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 128, None, 192)       384       ['concatenate_13[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 128, None, 192)       0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 128, None, 768)       147456    ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 128, None, 768)       1536      ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 128, None, 10)        7680      ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 128, None, 10)        20        ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 10)                   0         ['batch_normalization_73[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 10)                   0         ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3254468 (12.41 MB)\n",
            "Trainable params: 3247416 (12.39 MB)\n",
            "Non-trainable params: 7052 (27.55 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set learning rate schedule\n",
        "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(LM_train.shape[0]/batch_size), Tmult=2,\n",
        "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
        "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0,511.0])\n",
        "callbacks = [lr_scheduler]\n",
        "\n",
        "#create data generator\n",
        "TrainDataGen = MixupGenerator(LM_train,\n",
        "                              y_train,\n",
        "                              batch_size=batch_size,\n",
        "                              alpha=mixup_alpha,\n",
        "                              crop_length=crop_length)()\n",
        "\n",
        "#train the model\n",
        "history = model.fit_generator(TrainDataGen,\n",
        "                              validation_data=(LM_val, y_val),\n",
        "                              epochs=num_epochs,\n",
        "                              verbose=1,\n",
        "                              workers=4,\n",
        "                              max_queue_size = 100,\n",
        "                              callbacks=callbacks,\n",
        "                              steps_per_epoch=np.ceil(LM_train.shape[0]/batch_size)\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f62HazlDtGRC",
        "outputId": "02c9fc9e-fd12-491b-9900-6c6497152cbd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-41-f992368096ca>:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(TrainDataGen,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 8.2873 - accuracy: 0.4253\n",
            "LearningRate:0.050815\n",
            "97/97 [==============================] - 29s 174ms/step - loss: 8.2873 - accuracy: 0.4253 - val_loss: 10.4009 - val_accuracy: 0.1286\n",
            "Epoch 2/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 6.8672 - accuracy: 0.5219\n",
            "LearningRate:0.000017\n",
            "97/97 [==============================] - 12s 126ms/step - loss: 6.8672 - accuracy: 0.5219 - val_loss: 6.9585 - val_accuracy: 0.3029\n",
            "Epoch 3/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 6.0303 - accuracy: 0.5087\n",
            "LearningRate:0.085642\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 6.0303 - accuracy: 0.5087 - val_loss: 5.6451 - val_accuracy: 0.2523\n",
            "Epoch 4/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 4.7423 - accuracy: 0.5677\n",
            "LearningRate:0.050410\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 4.7423 - accuracy: 0.5677 - val_loss: 4.6614 - val_accuracy: 0.2714\n",
            "Epoch 5/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 4.0937 - accuracy: 0.6099\n",
            "LearningRate:0.014941\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 4.0937 - accuracy: 0.6099 - val_loss: 4.2215 - val_accuracy: 0.3701\n",
            "Epoch 6/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 3.8499 - accuracy: 0.6514\n",
            "LearningRate:0.000012\n",
            "97/97 [==============================] - 15s 150ms/step - loss: 3.8499 - accuracy: 0.6514 - val_loss: 3.8519 - val_accuracy: 0.5842\n",
            "Epoch 7/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 3.6330 - accuracy: 0.5673\n",
            "LearningRate:0.096271\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 3.6330 - accuracy: 0.5673 - val_loss: 3.3027 - val_accuracy: 0.4141\n",
            "Epoch 8/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 3.0163 - accuracy: 0.5841\n",
            "LearningRate:0.085500\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 3.0163 - accuracy: 0.5841 - val_loss: 2.8917 - val_accuracy: 0.4349\n",
            "Epoch 9/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.6091 - accuracy: 0.5931\n",
            "LearningRate:0.069324\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 2.6091 - accuracy: 0.5931 - val_loss: 2.5596 - val_accuracy: 0.5004\n",
            "Epoch 10/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.3320 - accuracy: 0.6350\n",
            "LearningRate:0.050207\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 2.3320 - accuracy: 0.6350 - val_loss: 2.4365 - val_accuracy: 0.4581\n",
            "Epoch 11/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.1682 - accuracy: 0.6572\n",
            "LearningRate:0.031060\n",
            "97/97 [==============================] - 20s 209ms/step - loss: 2.1682 - accuracy: 0.6572 - val_loss: 2.2500 - val_accuracy: 0.4996\n",
            "Epoch 12/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.0503 - accuracy: 0.6917\n",
            "LearningRate:0.014797\n",
            "97/97 [==============================] - 14s 140ms/step - loss: 2.0503 - accuracy: 0.6917 - val_loss: 2.0932 - val_accuracy: 0.5851\n",
            "Epoch 13/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.9744 - accuracy: 0.7055\n",
            "LearningRate:0.003893\n",
            "97/97 [==============================] - 15s 154ms/step - loss: 1.9744 - accuracy: 0.7055 - val_loss: 2.0012 - val_accuracy: 0.6207\n",
            "Epoch 14/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.9170 - accuracy: 0.7494\n",
            "LearningRate:0.000010\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.9170 - accuracy: 0.7494 - val_loss: 1.8312 - val_accuracy: 0.7046\n",
            "Epoch 15/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.0627 - accuracy: 0.6044\n",
            "LearningRate:0.099059\n",
            "97/97 [==============================] - 20s 207ms/step - loss: 2.0627 - accuracy: 0.6044 - val_loss: 2.3779 - val_accuracy: 0.3178\n",
            "Epoch 16/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.9384 - accuracy: 0.6198\n",
            "LearningRate:0.096233\n",
            "97/97 [==============================] - 13s 129ms/step - loss: 1.9384 - accuracy: 0.6198 - val_loss: 2.2841 - val_accuracy: 0.3477\n",
            "Epoch 17/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.8588 - accuracy: 0.6186\n",
            "LearningRate:0.091630\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.8588 - accuracy: 0.6186 - val_loss: 2.1495 - val_accuracy: 0.3344\n",
            "Epoch 18/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.7601 - accuracy: 0.6495\n",
            "LearningRate:0.085428\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.7601 - accuracy: 0.6495 - val_loss: 2.0226 - val_accuracy: 0.4531\n",
            "Epoch 19/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.7473 - accuracy: 0.6379\n",
            "LearningRate:0.077865\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.7473 - accuracy: 0.6379 - val_loss: 1.8131 - val_accuracy: 0.5344\n",
            "Epoch 20/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6920 - accuracy: 0.6685\n",
            "LearningRate:0.069231\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.6920 - accuracy: 0.6685 - val_loss: 1.6355 - val_accuracy: 0.6000\n",
            "Epoch 21/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6625 - accuracy: 0.6756\n",
            "LearningRate:0.059858\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.6625 - accuracy: 0.6756 - val_loss: 1.5957 - val_accuracy: 0.6647\n",
            "Epoch 22/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6325 - accuracy: 0.6746\n",
            "LearningRate:0.050106\n",
            "97/97 [==============================] - 15s 158ms/step - loss: 1.6325 - accuracy: 0.6746 - val_loss: 1.6684 - val_accuracy: 0.5245\n",
            "Epoch 23/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5832 - accuracy: 0.6962\n",
            "LearningRate:0.040351\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.5832 - accuracy: 0.6962 - val_loss: 1.7609 - val_accuracy: 0.5560\n",
            "Epoch 24/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5501 - accuracy: 0.7252\n",
            "LearningRate:0.030966\n",
            "97/97 [==============================] - 19s 198ms/step - loss: 1.5501 - accuracy: 0.7252 - val_loss: 1.8324 - val_accuracy: 0.4199\n",
            "Epoch 25/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.7465\n",
            "LearningRate:0.022313\n",
            "97/97 [==============================] - 13s 136ms/step - loss: 1.5095 - accuracy: 0.7465 - val_loss: 1.6095 - val_accuracy: 0.6539\n",
            "Epoch 26/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 0.7674\n",
            "LearningRate:0.014725\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.4707 - accuracy: 0.7674 - val_loss: 1.5247 - val_accuracy: 0.6539\n",
            "Epoch 27/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4375 - accuracy: 0.7845\n",
            "LearningRate:0.008492\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.4375 - accuracy: 0.7845 - val_loss: 1.5191 - val_accuracy: 0.6763\n",
            "Epoch 28/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4054 - accuracy: 0.7948\n",
            "LearningRate:0.003854\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.4054 - accuracy: 0.7948 - val_loss: 1.3969 - val_accuracy: 0.7004\n",
            "Epoch 29/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3736 - accuracy: 0.8183\n",
            "LearningRate:0.000990\n",
            "97/97 [==============================] - 22s 224ms/step - loss: 1.3736 - accuracy: 0.8183 - val_loss: 1.3362 - val_accuracy: 0.7228\n",
            "Epoch 30/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3638 - accuracy: 0.8322\n",
            "LearningRate:0.000010\n",
            "97/97 [==============================] - 11s 111ms/step - loss: 1.3638 - accuracy: 0.8322 - val_loss: 1.2644 - val_accuracy: 0.7436\n",
            "Epoch 31/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6699 - accuracy: 0.6476\n",
            "LearningRate:0.099764\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.6699 - accuracy: 0.6476 - val_loss: 8.2740 - val_accuracy: 0.0888\n",
            "Epoch 32/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6753 - accuracy: 0.6517\n",
            "LearningRate:0.099049\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.6753 - accuracy: 0.6517 - val_loss: 1.9114 - val_accuracy: 0.4108\n",
            "Epoch 33/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6439 - accuracy: 0.6678\n",
            "LearningRate:0.097862\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.6439 - accuracy: 0.6678 - val_loss: 1.6240 - val_accuracy: 0.5295\n",
            "Epoch 34/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6278 - accuracy: 0.6782\n",
            "LearningRate:0.096214\n",
            "97/97 [==============================] - 14s 148ms/step - loss: 1.6278 - accuracy: 0.6782 - val_loss: 1.7044 - val_accuracy: 0.5120\n",
            "Epoch 35/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6268 - accuracy: 0.6804\n",
            "LearningRate:0.094120\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.6268 - accuracy: 0.6804 - val_loss: 1.6666 - val_accuracy: 0.5195\n",
            "Epoch 36/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6266 - accuracy: 0.6830\n",
            "LearningRate:0.091602\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.6266 - accuracy: 0.6830 - val_loss: 1.6841 - val_accuracy: 0.4946\n",
            "Epoch 37/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6179 - accuracy: 0.6849\n",
            "LearningRate:0.088684\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.6179 - accuracy: 0.6849 - val_loss: 1.7622 - val_accuracy: 0.4639\n",
            "Epoch 38/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5832 - accuracy: 0.7062\n",
            "LearningRate:0.085393\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.5832 - accuracy: 0.7062 - val_loss: 1.8110 - val_accuracy: 0.4672\n",
            "Epoch 39/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5922 - accuracy: 0.7023\n",
            "LearningRate:0.081761\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.5922 - accuracy: 0.7023 - val_loss: 1.7423 - val_accuracy: 0.4813\n",
            "Epoch 40/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5997 - accuracy: 0.7010\n",
            "LearningRate:0.077823\n",
            "97/97 [==============================] - 13s 134ms/step - loss: 1.5997 - accuracy: 0.7010 - val_loss: 1.6644 - val_accuracy: 0.5419\n",
            "Epoch 41/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5764 - accuracy: 0.7262\n",
            "LearningRate:0.073617\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.5764 - accuracy: 0.7262 - val_loss: 1.7134 - val_accuracy: 0.4689\n",
            "Epoch 42/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5671 - accuracy: 0.7178\n",
            "LearningRate:0.069184\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.5671 - accuracy: 0.7178 - val_loss: 1.6062 - val_accuracy: 0.6398\n",
            "Epoch 43/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5366 - accuracy: 0.7426\n",
            "LearningRate:0.064566\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.5366 - accuracy: 0.7426 - val_loss: 1.8310 - val_accuracy: 0.3859\n",
            "Epoch 44/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.7284\n",
            "LearningRate:0.059808\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.5409 - accuracy: 0.7284 - val_loss: 1.5578 - val_accuracy: 0.5693\n",
            "Epoch 45/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5027 - accuracy: 0.7490\n",
            "LearningRate:0.054956\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.5027 - accuracy: 0.7490 - val_loss: 1.7573 - val_accuracy: 0.4929\n",
            "Epoch 46/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5063 - accuracy: 0.7452\n",
            "LearningRate:0.050056\n",
            "97/97 [==============================] - 15s 154ms/step - loss: 1.5063 - accuracy: 0.7452 - val_loss: 1.7357 - val_accuracy: 0.4282\n",
            "Epoch 47/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4997 - accuracy: 0.7555\n",
            "LearningRate:0.045155\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.4997 - accuracy: 0.7555 - val_loss: 1.5272 - val_accuracy: 0.6705\n",
            "Epoch 48/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4859 - accuracy: 0.7542\n",
            "LearningRate:0.040301\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.4859 - accuracy: 0.7542 - val_loss: 1.5022 - val_accuracy: 0.6158\n",
            "Epoch 49/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.7774\n",
            "LearningRate:0.035541\n",
            "97/97 [==============================] - 13s 137ms/step - loss: 1.4693 - accuracy: 0.7774 - val_loss: 1.5969 - val_accuracy: 0.5793\n",
            "Epoch 50/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4288 - accuracy: 0.7916\n",
            "LearningRate:0.030919\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.4288 - accuracy: 0.7916 - val_loss: 1.5416 - val_accuracy: 0.5510\n",
            "Epoch 51/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4161 - accuracy: 0.8025\n",
            "LearningRate:0.026482\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.4161 - accuracy: 0.8025 - val_loss: 1.5253 - val_accuracy: 0.6199\n",
            "Epoch 52/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3953 - accuracy: 0.8180\n",
            "LearningRate:0.022271\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.3953 - accuracy: 0.8180 - val_loss: 1.5158 - val_accuracy: 0.6315\n",
            "Epoch 53/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3706 - accuracy: 0.8206\n",
            "LearningRate:0.018328\n",
            "97/97 [==============================] - 14s 149ms/step - loss: 1.3706 - accuracy: 0.8206 - val_loss: 1.4677 - val_accuracy: 0.6988\n",
            "Epoch 54/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3441 - accuracy: 0.8354\n",
            "LearningRate:0.014689\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.3441 - accuracy: 0.8354 - val_loss: 1.6087 - val_accuracy: 0.5826\n",
            "Epoch 55/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3361 - accuracy: 0.8392\n",
            "LearningRate:0.011390\n",
            "97/97 [==============================] - 15s 152ms/step - loss: 1.3361 - accuracy: 0.8392 - val_loss: 1.4339 - val_accuracy: 0.6415\n",
            "Epoch 56/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2930 - accuracy: 0.8611\n",
            "LearningRate:0.008464\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.2930 - accuracy: 0.8611 - val_loss: 1.3934 - val_accuracy: 0.6996\n",
            "Epoch 57/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2842 - accuracy: 0.8566\n",
            "LearningRate:0.005937\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.2842 - accuracy: 0.8566 - val_loss: 1.3040 - val_accuracy: 0.7253\n",
            "Epoch 58/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2629 - accuracy: 0.8676\n",
            "LearningRate:0.003835\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.2629 - accuracy: 0.8676 - val_loss: 1.3151 - val_accuracy: 0.6971\n",
            "Epoch 59/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2440 - accuracy: 0.8698\n",
            "LearningRate:0.002177\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.2440 - accuracy: 0.8698 - val_loss: 1.2556 - val_accuracy: 0.7469\n",
            "Epoch 60/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2391 - accuracy: 0.8721\n",
            "LearningRate:0.000981\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.2391 - accuracy: 0.8721 - val_loss: 1.2160 - val_accuracy: 0.7685\n",
            "Epoch 61/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2339 - accuracy: 0.8792\n",
            "LearningRate:0.000256\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.2339 - accuracy: 0.8792 - val_loss: 1.1922 - val_accuracy: 0.7710\n",
            "Epoch 62/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2356 - accuracy: 0.8782\n",
            "LearningRate:0.000010\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.2356 - accuracy: 0.8782 - val_loss: 1.1754 - val_accuracy: 0.7701\n",
            "Epoch 63/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6609 - accuracy: 0.6517\n",
            "LearningRate:0.099941\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.6609 - accuracy: 0.6517 - val_loss: 3.8051 - val_accuracy: 0.2432\n",
            "Epoch 64/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6275 - accuracy: 0.6836\n",
            "LearningRate:0.099762\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.6275 - accuracy: 0.6836 - val_loss: 2.2444 - val_accuracy: 0.3253\n",
            "Epoch 65/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6468 - accuracy: 0.6852\n",
            "LearningRate:0.099463\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.6468 - accuracy: 0.6852 - val_loss: 1.8667 - val_accuracy: 0.4556\n",
            "Epoch 66/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6101 - accuracy: 0.7107\n",
            "LearningRate:0.099044\n",
            "97/97 [==============================] - 14s 149ms/step - loss: 1.6101 - accuracy: 0.7107 - val_loss: 1.5631 - val_accuracy: 0.6166\n",
            "Epoch 67/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6040 - accuracy: 0.7181\n",
            "LearningRate:0.098508\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.6040 - accuracy: 0.7181 - val_loss: 1.6057 - val_accuracy: 0.5734\n",
            "Epoch 68/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6014 - accuracy: 0.7055\n",
            "LearningRate:0.097855\n",
            "97/97 [==============================] - 20s 203ms/step - loss: 1.6014 - accuracy: 0.7055 - val_loss: 1.7685 - val_accuracy: 0.4788\n",
            "Epoch 69/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6441 - accuracy: 0.7033\n",
            "LearningRate:0.097086\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.6441 - accuracy: 0.7033 - val_loss: 1.7930 - val_accuracy: 0.4465\n",
            "Epoch 70/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5970 - accuracy: 0.7258\n",
            "LearningRate:0.096204\n",
            "97/97 [==============================] - 12s 126ms/step - loss: 1.5970 - accuracy: 0.7258 - val_loss: 1.7275 - val_accuracy: 0.5610\n",
            "Epoch 71/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 0.7229\n",
            "LearningRate:0.095211\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.5927 - accuracy: 0.7229 - val_loss: 2.0809 - val_accuracy: 0.3095\n",
            "Epoch 72/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5806 - accuracy: 0.7365\n",
            "LearningRate:0.094109\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.5806 - accuracy: 0.7365 - val_loss: 1.7563 - val_accuracy: 0.4880\n",
            "Epoch 73/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5969 - accuracy: 0.7342\n",
            "LearningRate:0.092900\n",
            "97/97 [==============================] - 13s 131ms/step - loss: 1.5969 - accuracy: 0.7342 - val_loss: 1.9726 - val_accuracy: 0.4108\n",
            "Epoch 74/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5799 - accuracy: 0.7336\n",
            "LearningRate:0.091588\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.5799 - accuracy: 0.7336 - val_loss: 1.9116 - val_accuracy: 0.4390\n",
            "Epoch 75/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5891 - accuracy: 0.7320\n",
            "LearningRate:0.090176\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.5891 - accuracy: 0.7320 - val_loss: 1.6586 - val_accuracy: 0.5842\n",
            "Epoch 76/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5746 - accuracy: 0.7436\n",
            "LearningRate:0.088668\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.5746 - accuracy: 0.7436 - val_loss: 1.7905 - val_accuracy: 0.4481\n",
            "Epoch 77/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5570 - accuracy: 0.7436\n",
            "LearningRate:0.087066\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.5570 - accuracy: 0.7436 - val_loss: 2.0580 - val_accuracy: 0.3560\n",
            "Epoch 78/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5362 - accuracy: 0.7545\n",
            "LearningRate:0.085375\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.5362 - accuracy: 0.7545 - val_loss: 1.6653 - val_accuracy: 0.5394\n",
            "Epoch 79/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5595 - accuracy: 0.7500\n",
            "LearningRate:0.083598\n",
            "97/97 [==============================] - 14s 149ms/step - loss: 1.5595 - accuracy: 0.7500 - val_loss: 1.7104 - val_accuracy: 0.5411\n",
            "Epoch 80/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5381 - accuracy: 0.7552\n",
            "LearningRate:0.081741\n",
            "97/97 [==============================] - 17s 179ms/step - loss: 1.5381 - accuracy: 0.7552 - val_loss: 1.5417 - val_accuracy: 0.5867\n",
            "Epoch 81/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5591 - accuracy: 0.7529\n",
            "LearningRate:0.079807\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.5591 - accuracy: 0.7529 - val_loss: 2.4371 - val_accuracy: 0.2050\n",
            "Epoch 82/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5405 - accuracy: 0.7532\n",
            "LearningRate:0.077802\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.5405 - accuracy: 0.7532 - val_loss: 1.8902 - val_accuracy: 0.3851\n",
            "Epoch 83/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5523 - accuracy: 0.7526\n",
            "LearningRate:0.075729\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.5523 - accuracy: 0.7526 - val_loss: 1.6353 - val_accuracy: 0.5834\n",
            "Epoch 84/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5336 - accuracy: 0.7677\n",
            "LearningRate:0.073595\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.5336 - accuracy: 0.7677 - val_loss: 1.9030 - val_accuracy: 0.4589\n",
            "Epoch 85/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 0.7671\n",
            "LearningRate:0.071403\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.5333 - accuracy: 0.7671 - val_loss: 1.7890 - val_accuracy: 0.4631\n",
            "Epoch 86/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5097 - accuracy: 0.7680\n",
            "LearningRate:0.069161\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.5097 - accuracy: 0.7680 - val_loss: 1.7012 - val_accuracy: 0.5187\n",
            "Epoch 87/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4945 - accuracy: 0.7803\n",
            "LearningRate:0.066872\n",
            "97/97 [==============================] - 20s 207ms/step - loss: 1.4945 - accuracy: 0.7803 - val_loss: 1.7723 - val_accuracy: 0.5037\n",
            "Epoch 88/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4956 - accuracy: 0.7784\n",
            "LearningRate:0.064542\n",
            "97/97 [==============================] - 12s 125ms/step - loss: 1.4956 - accuracy: 0.7784 - val_loss: 1.6460 - val_accuracy: 0.5278\n",
            "Epoch 89/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4879 - accuracy: 0.7874\n",
            "LearningRate:0.062177\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.4879 - accuracy: 0.7874 - val_loss: 1.6509 - val_accuracy: 0.5909\n",
            "Epoch 90/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4809 - accuracy: 0.7803\n",
            "LearningRate:0.059783\n",
            "97/97 [==============================] - 17s 179ms/step - loss: 1.4809 - accuracy: 0.7803 - val_loss: 1.8260 - val_accuracy: 0.3959\n",
            "Epoch 91/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4753 - accuracy: 0.7864\n",
            "LearningRate:0.057366\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.4753 - accuracy: 0.7864 - val_loss: 1.7835 - val_accuracy: 0.5378\n",
            "Epoch 92/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4816 - accuracy: 0.7967\n",
            "LearningRate:0.054931\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.4816 - accuracy: 0.7967 - val_loss: 1.7462 - val_accuracy: 0.4747\n",
            "Epoch 93/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4539 - accuracy: 0.8015\n",
            "LearningRate:0.052483\n",
            "97/97 [==============================] - 14s 144ms/step - loss: 1.4539 - accuracy: 0.8015 - val_loss: 1.7021 - val_accuracy: 0.5154\n",
            "Epoch 94/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4464 - accuracy: 0.8054\n",
            "LearningRate:0.050030\n",
            "97/97 [==============================] - 21s 220ms/step - loss: 1.4464 - accuracy: 0.8054 - val_loss: 1.5708 - val_accuracy: 0.6216\n",
            "Epoch 95/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4536 - accuracy: 0.7928\n",
            "LearningRate:0.047577\n",
            "97/97 [==============================] - 12s 124ms/step - loss: 1.4536 - accuracy: 0.7928 - val_loss: 1.5832 - val_accuracy: 0.6606\n",
            "Epoch 96/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4371 - accuracy: 0.8125\n",
            "LearningRate:0.045130\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.4371 - accuracy: 0.8125 - val_loss: 1.5860 - val_accuracy: 0.6481\n",
            "Epoch 97/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4206 - accuracy: 0.7957\n",
            "LearningRate:0.042694\n",
            "97/97 [==============================] - 17s 181ms/step - loss: 1.4206 - accuracy: 0.7957 - val_loss: 1.7329 - val_accuracy: 0.4598\n",
            "Epoch 98/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4129 - accuracy: 0.8022\n",
            "LearningRate:0.040276\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 1.4129 - accuracy: 0.8022 - val_loss: 1.5559 - val_accuracy: 0.5851\n",
            "Epoch 99/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3855 - accuracy: 0.8235\n",
            "LearningRate:0.037882\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3855 - accuracy: 0.8235 - val_loss: 1.6305 - val_accuracy: 0.5710\n",
            "Epoch 100/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3867 - accuracy: 0.8315\n",
            "LearningRate:0.035516\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.3867 - accuracy: 0.8315 - val_loss: 1.6283 - val_accuracy: 0.5909\n",
            "Epoch 101/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3788 - accuracy: 0.8312\n",
            "LearningRate:0.033186\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.3788 - accuracy: 0.8312 - val_loss: 1.6248 - val_accuracy: 0.5602\n",
            "Epoch 102/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3713 - accuracy: 0.8341\n",
            "LearningRate:0.030896\n",
            "97/97 [==============================] - 21s 214ms/step - loss: 1.3713 - accuracy: 0.8341 - val_loss: 1.6644 - val_accuracy: 0.5154\n",
            "Epoch 103/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3338 - accuracy: 0.8434\n",
            "LearningRate:0.028652\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.3338 - accuracy: 0.8434 - val_loss: 1.5371 - val_accuracy: 0.6622\n",
            "Epoch 104/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3380 - accuracy: 0.8460\n",
            "LearningRate:0.026460\n",
            "97/97 [==============================] - 13s 130ms/step - loss: 1.3380 - accuracy: 0.8460 - val_loss: 1.5771 - val_accuracy: 0.6257\n",
            "Epoch 105/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3361 - accuracy: 0.8447\n",
            "LearningRate:0.024324\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.3361 - accuracy: 0.8447 - val_loss: 1.4332 - val_accuracy: 0.6913\n",
            "Epoch 106/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3116 - accuracy: 0.8502\n",
            "LearningRate:0.022250\n",
            "97/97 [==============================] - 21s 213ms/step - loss: 1.3116 - accuracy: 0.8502 - val_loss: 1.4966 - val_accuracy: 0.6066\n",
            "Epoch 107/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3078 - accuracy: 0.8566\n",
            "LearningRate:0.020243\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 1.3078 - accuracy: 0.8566 - val_loss: 1.4819 - val_accuracy: 0.6274\n",
            "Epoch 108/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2944 - accuracy: 0.8595\n",
            "LearningRate:0.018308\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.2944 - accuracy: 0.8595 - val_loss: 1.4899 - val_accuracy: 0.6739\n",
            "Epoch 109/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2811 - accuracy: 0.8624\n",
            "LearningRate:0.016449\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.2811 - accuracy: 0.8624 - val_loss: 1.4855 - val_accuracy: 0.6490\n",
            "Epoch 110/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2517 - accuracy: 0.8734\n",
            "LearningRate:0.014671\n",
            "97/97 [==============================] - 19s 199ms/step - loss: 1.2517 - accuracy: 0.8734 - val_loss: 1.2943 - val_accuracy: 0.7378\n",
            "Epoch 111/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2537 - accuracy: 0.8727\n",
            "LearningRate:0.012978\n",
            "97/97 [==============================] - 14s 143ms/step - loss: 1.2537 - accuracy: 0.8727 - val_loss: 1.4888 - val_accuracy: 0.6058\n",
            "Epoch 112/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2402 - accuracy: 0.8892\n",
            "LearningRate:0.011374\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2402 - accuracy: 0.8892 - val_loss: 1.3996 - val_accuracy: 0.6689\n",
            "Epoch 113/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2416 - accuracy: 0.8782\n",
            "LearningRate:0.009864\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.2416 - accuracy: 0.8782 - val_loss: 1.4242 - val_accuracy: 0.6855\n",
            "Epoch 114/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2086 - accuracy: 0.8943\n",
            "LearningRate:0.008450\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 1.2086 - accuracy: 0.8943 - val_loss: 1.3176 - val_accuracy: 0.7270\n",
            "Epoch 115/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2031 - accuracy: 0.8834\n",
            "LearningRate:0.007136\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.2031 - accuracy: 0.8834 - val_loss: 1.2930 - val_accuracy: 0.7602\n",
            "Epoch 116/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1759 - accuracy: 0.8988\n",
            "LearningRate:0.005925\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.1759 - accuracy: 0.8988 - val_loss: 1.2920 - val_accuracy: 0.7461\n",
            "Epoch 117/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1636 - accuracy: 0.9027\n",
            "LearningRate:0.004821\n",
            "97/97 [==============================] - 14s 140ms/step - loss: 1.1636 - accuracy: 0.9027 - val_loss: 1.2822 - val_accuracy: 0.7170\n",
            "Epoch 118/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1841 - accuracy: 0.8988\n",
            "LearningRate:0.003825\n",
            "97/97 [==============================] - 23s 234ms/step - loss: 1.1841 - accuracy: 0.8988 - val_loss: 1.2527 - val_accuracy: 0.7419\n",
            "Epoch 119/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1394 - accuracy: 0.9133\n",
            "LearningRate:0.002941\n",
            "97/97 [==============================] - 11s 109ms/step - loss: 1.1394 - accuracy: 0.9133 - val_loss: 1.2958 - val_accuracy: 0.7452\n",
            "Epoch 120/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1507 - accuracy: 0.9146\n",
            "LearningRate:0.002170\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.1507 - accuracy: 0.9146 - val_loss: 1.2489 - val_accuracy: 0.7568\n",
            "Epoch 121/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1263 - accuracy: 0.9130\n",
            "LearningRate:0.001514\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.1263 - accuracy: 0.9130 - val_loss: 1.2138 - val_accuracy: 0.7734\n",
            "Epoch 122/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1381 - accuracy: 0.9075\n",
            "LearningRate:0.000976\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.1381 - accuracy: 0.9075 - val_loss: 1.2144 - val_accuracy: 0.7718\n",
            "Epoch 123/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1196 - accuracy: 0.9166\n",
            "LearningRate:0.000555\n",
            "97/97 [==============================] - 14s 142ms/step - loss: 1.1196 - accuracy: 0.9166 - val_loss: 1.2039 - val_accuracy: 0.7643\n",
            "Epoch 124/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1342 - accuracy: 0.9091\n",
            "LearningRate:0.000253\n",
            "97/97 [==============================] - 20s 211ms/step - loss: 1.1342 - accuracy: 0.9091 - val_loss: 1.1776 - val_accuracy: 0.7710\n",
            "Epoch 125/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1309 - accuracy: 0.9127\n",
            "LearningRate:0.000071\n",
            "97/97 [==============================] - 15s 158ms/step - loss: 1.1309 - accuracy: 0.9127 - val_loss: 1.1759 - val_accuracy: 0.7743\n",
            "Epoch 126/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1266 - accuracy: 0.9120\n",
            "LearningRate:0.000010\n",
            "97/97 [==============================] - 12s 129ms/step - loss: 1.1266 - accuracy: 0.9120 - val_loss: 1.1700 - val_accuracy: 0.7784\n",
            "Epoch 127/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.7251 - accuracy: 0.6231\n",
            "LearningRate:0.099985\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.7251 - accuracy: 0.6231 - val_loss: 9.7837 - val_accuracy: 0.1676\n",
            "Epoch 128/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6809 - accuracy: 0.6691\n",
            "LearningRate:0.099940\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.6809 - accuracy: 0.6691 - val_loss: 2.5214 - val_accuracy: 0.2714\n",
            "Epoch 129/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6517 - accuracy: 0.6859\n",
            "LearningRate:0.099865\n",
            "97/97 [==============================] - 23s 236ms/step - loss: 1.6517 - accuracy: 0.6859 - val_loss: 1.8799 - val_accuracy: 0.4349\n",
            "Epoch 130/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6177 - accuracy: 0.7049\n",
            "LearningRate:0.099760\n",
            "97/97 [==============================] - 11s 109ms/step - loss: 1.6177 - accuracy: 0.7049 - val_loss: 1.6877 - val_accuracy: 0.4988\n",
            "Epoch 131/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5963 - accuracy: 0.7200\n",
            "LearningRate:0.099626\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 1.5963 - accuracy: 0.7200 - val_loss: 1.9949 - val_accuracy: 0.2880\n",
            "Epoch 132/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5963 - accuracy: 0.7255\n",
            "LearningRate:0.099461\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.5963 - accuracy: 0.7255 - val_loss: 1.7982 - val_accuracy: 0.4573\n",
            "Epoch 133/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5719 - accuracy: 0.7390\n",
            "LearningRate:0.099266\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.5719 - accuracy: 0.7390 - val_loss: 1.9262 - val_accuracy: 0.3328\n",
            "Epoch 134/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5688 - accuracy: 0.7516\n",
            "LearningRate:0.099042\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.5688 - accuracy: 0.7516 - val_loss: 1.7908 - val_accuracy: 0.4963\n",
            "Epoch 135/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5710 - accuracy: 0.7432\n",
            "LearningRate:0.098788\n",
            "97/97 [==============================] - 14s 141ms/step - loss: 1.5710 - accuracy: 0.7432 - val_loss: 2.0223 - val_accuracy: 0.2838\n",
            "Epoch 136/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5803 - accuracy: 0.7365\n",
            "LearningRate:0.098505\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.5803 - accuracy: 0.7365 - val_loss: 1.7590 - val_accuracy: 0.4697\n",
            "Epoch 137/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5642 - accuracy: 0.7558\n",
            "LearningRate:0.098192\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.5642 - accuracy: 0.7558 - val_loss: 2.0428 - val_accuracy: 0.3535\n",
            "Epoch 138/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5879 - accuracy: 0.7378\n",
            "LearningRate:0.097851\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.5879 - accuracy: 0.7378 - val_loss: 1.7464 - val_accuracy: 0.5079\n",
            "Epoch 139/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5652 - accuracy: 0.7523\n",
            "LearningRate:0.097481\n",
            "97/97 [==============================] - 13s 135ms/step - loss: 1.5652 - accuracy: 0.7523 - val_loss: 2.1048 - val_accuracy: 0.3037\n",
            "Epoch 140/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.7542\n",
            "LearningRate:0.097082\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.5695 - accuracy: 0.7542 - val_loss: 2.0049 - val_accuracy: 0.3386\n",
            "Epoch 141/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.7436\n",
            "LearningRate:0.096655\n",
            "97/97 [==============================] - 19s 201ms/step - loss: 1.5732 - accuracy: 0.7436 - val_loss: 2.0294 - val_accuracy: 0.3469\n",
            "Epoch 142/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5487 - accuracy: 0.7655\n",
            "LearningRate:0.096199\n",
            "97/97 [==============================] - 14s 143ms/step - loss: 1.5487 - accuracy: 0.7655 - val_loss: 1.7009 - val_accuracy: 0.5286\n",
            "Epoch 143/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5571 - accuracy: 0.7642\n",
            "LearningRate:0.095716\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.5571 - accuracy: 0.7642 - val_loss: 1.8185 - val_accuracy: 0.4000\n",
            "Epoch 144/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5617 - accuracy: 0.7613\n",
            "LearningRate:0.095205\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.5617 - accuracy: 0.7613 - val_loss: 1.7975 - val_accuracy: 0.4979\n",
            "Epoch 145/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5601 - accuracy: 0.7571\n",
            "LearningRate:0.094667\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.5601 - accuracy: 0.7571 - val_loss: 1.8390 - val_accuracy: 0.4100\n",
            "Epoch 146/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5628 - accuracy: 0.7526\n",
            "LearningRate:0.094103\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.5628 - accuracy: 0.7526 - val_loss: 2.1733 - val_accuracy: 0.2855\n",
            "Epoch 147/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.7635\n",
            "LearningRate:0.093511\n",
            "97/97 [==============================] - 13s 136ms/step - loss: 1.5732 - accuracy: 0.7635 - val_loss: 1.9029 - val_accuracy: 0.4639\n",
            "Epoch 148/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.7735\n",
            "LearningRate:0.092894\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 1.5320 - accuracy: 0.7735 - val_loss: 1.7765 - val_accuracy: 0.5112\n",
            "Epoch 149/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5556 - accuracy: 0.7581\n",
            "LearningRate:0.092250\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.5556 - accuracy: 0.7581 - val_loss: 1.7289 - val_accuracy: 0.5286\n",
            "Epoch 150/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5393 - accuracy: 0.7706\n",
            "LearningRate:0.091581\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.5393 - accuracy: 0.7706 - val_loss: 1.7549 - val_accuracy: 0.4581\n",
            "Epoch 151/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5604 - accuracy: 0.7619\n",
            "LearningRate:0.090887\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 1.5604 - accuracy: 0.7619 - val_loss: 1.8865 - val_accuracy: 0.4315\n",
            "Epoch 152/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5608 - accuracy: 0.7571\n",
            "LearningRate:0.090169\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.5608 - accuracy: 0.7571 - val_loss: 1.7010 - val_accuracy: 0.5900\n",
            "Epoch 153/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5602 - accuracy: 0.7687\n",
            "LearningRate:0.089426\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.5602 - accuracy: 0.7687 - val_loss: 2.0405 - val_accuracy: 0.2963\n",
            "Epoch 154/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5627 - accuracy: 0.7619\n",
            "LearningRate:0.088660\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.5627 - accuracy: 0.7619 - val_loss: 2.3719 - val_accuracy: 0.2888\n",
            "Epoch 155/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5481 - accuracy: 0.7680\n",
            "LearningRate:0.087870\n",
            "97/97 [==============================] - 13s 139ms/step - loss: 1.5481 - accuracy: 0.7680 - val_loss: 1.8217 - val_accuracy: 0.4481\n",
            "Epoch 156/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5241 - accuracy: 0.7761\n",
            "LearningRate:0.087057\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.5241 - accuracy: 0.7761 - val_loss: 1.7772 - val_accuracy: 0.5178\n",
            "Epoch 157/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5395 - accuracy: 0.7793\n",
            "LearningRate:0.086222\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 1.5395 - accuracy: 0.7793 - val_loss: 1.8717 - val_accuracy: 0.4689\n",
            "Epoch 158/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5151 - accuracy: 0.7854\n",
            "LearningRate:0.085366\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.5151 - accuracy: 0.7854 - val_loss: 2.0166 - val_accuracy: 0.3784\n",
            "Epoch 159/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5407 - accuracy: 0.7832\n",
            "LearningRate:0.084488\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.5407 - accuracy: 0.7832 - val_loss: 1.9029 - val_accuracy: 0.3759\n",
            "Epoch 160/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5355 - accuracy: 0.7697\n",
            "LearningRate:0.083589\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.5355 - accuracy: 0.7697 - val_loss: 1.6885 - val_accuracy: 0.5859\n",
            "Epoch 161/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5267 - accuracy: 0.7812\n",
            "LearningRate:0.082670\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.5267 - accuracy: 0.7812 - val_loss: 1.6305 - val_accuracy: 0.5610\n",
            "Epoch 162/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5187 - accuracy: 0.7793\n",
            "LearningRate:0.081731\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.5187 - accuracy: 0.7793 - val_loss: 1.6635 - val_accuracy: 0.6091\n",
            "Epoch 163/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5150 - accuracy: 0.7793\n",
            "LearningRate:0.080773\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.5150 - accuracy: 0.7793 - val_loss: 1.8824 - val_accuracy: 0.4058\n",
            "Epoch 164/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5142 - accuracy: 0.7829\n",
            "LearningRate:0.079797\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.5142 - accuracy: 0.7829 - val_loss: 1.8264 - val_accuracy: 0.4979\n",
            "Epoch 165/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5046 - accuracy: 0.7841\n",
            "LearningRate:0.078803\n",
            "97/97 [==============================] - 13s 135ms/step - loss: 1.5046 - accuracy: 0.7841 - val_loss: 1.9271 - val_accuracy: 0.3651\n",
            "Epoch 166/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.7848\n",
            "LearningRate:0.077791\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.5095 - accuracy: 0.7848 - val_loss: 1.7882 - val_accuracy: 0.4822\n",
            "Epoch 167/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4961 - accuracy: 0.7983\n",
            "LearningRate:0.076763\n",
            "97/97 [==============================] - 15s 158ms/step - loss: 1.4961 - accuracy: 0.7983 - val_loss: 1.7651 - val_accuracy: 0.5228\n",
            "Epoch 168/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4972 - accuracy: 0.7912\n",
            "LearningRate:0.075718\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.4972 - accuracy: 0.7912 - val_loss: 1.7751 - val_accuracy: 0.4722\n",
            "Epoch 169/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5020 - accuracy: 0.7941\n",
            "LearningRate:0.074658\n",
            "97/97 [==============================] - 21s 215ms/step - loss: 1.5020 - accuracy: 0.7941 - val_loss: 1.9202 - val_accuracy: 0.4174\n",
            "Epoch 170/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4891 - accuracy: 0.8048\n",
            "LearningRate:0.073584\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 1.4891 - accuracy: 0.8048 - val_loss: 1.8193 - val_accuracy: 0.4863\n",
            "Epoch 171/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5070 - accuracy: 0.7825\n",
            "LearningRate:0.072495\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.5070 - accuracy: 0.7825 - val_loss: 1.8986 - val_accuracy: 0.4008\n",
            "Epoch 172/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4960 - accuracy: 0.8038\n",
            "LearningRate:0.071392\n",
            "97/97 [==============================] - 24s 252ms/step - loss: 1.4960 - accuracy: 0.8038 - val_loss: 1.6719 - val_accuracy: 0.4913\n",
            "Epoch 173/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5049 - accuracy: 0.7948\n",
            "LearningRate:0.070277\n",
            "97/97 [==============================] - 11s 110ms/step - loss: 1.5049 - accuracy: 0.7948 - val_loss: 1.6951 - val_accuracy: 0.5535\n",
            "Epoch 174/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4777 - accuracy: 0.8051\n",
            "LearningRate:0.069149\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 1.4777 - accuracy: 0.8051 - val_loss: 1.6309 - val_accuracy: 0.5693\n",
            "Epoch 175/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 0.8044\n",
            "LearningRate:0.068010\n",
            "97/97 [==============================] - 19s 193ms/step - loss: 1.4707 - accuracy: 0.8044 - val_loss: 1.8300 - val_accuracy: 0.4515\n",
            "Epoch 176/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4835 - accuracy: 0.7977\n",
            "LearningRate:0.066860\n",
            "97/97 [==============================] - 15s 150ms/step - loss: 1.4835 - accuracy: 0.7977 - val_loss: 1.7223 - val_accuracy: 0.5676\n",
            "Epoch 177/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4757 - accuracy: 0.7945\n",
            "LearningRate:0.065700\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.4757 - accuracy: 0.7945 - val_loss: 1.9342 - val_accuracy: 0.3427\n",
            "Epoch 178/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.8073\n",
            "LearningRate:0.064530\n",
            "97/97 [==============================] - 14s 149ms/step - loss: 1.4613 - accuracy: 0.8073 - val_loss: 1.8084 - val_accuracy: 0.4772\n",
            "Epoch 179/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4640 - accuracy: 0.8128\n",
            "LearningRate:0.063351\n",
            "97/97 [==============================] - 17s 178ms/step - loss: 1.4640 - accuracy: 0.8128 - val_loss: 1.6711 - val_accuracy: 0.5568\n",
            "Epoch 180/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4678 - accuracy: 0.8019\n",
            "LearningRate:0.062165\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.4678 - accuracy: 0.8019 - val_loss: 1.6279 - val_accuracy: 0.5544\n",
            "Epoch 181/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4545 - accuracy: 0.8048\n",
            "LearningRate:0.060971\n",
            "97/97 [==============================] - 18s 181ms/step - loss: 1.4545 - accuracy: 0.8048 - val_loss: 1.5772 - val_accuracy: 0.6183\n",
            "Epoch 182/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4614 - accuracy: 0.8070\n",
            "LearningRate:0.059771\n",
            "97/97 [==============================] - 18s 191ms/step - loss: 1.4614 - accuracy: 0.8070 - val_loss: 1.9028 - val_accuracy: 0.3834\n",
            "Epoch 183/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4476 - accuracy: 0.8044\n",
            "LearningRate:0.058565\n",
            "97/97 [==============================] - 20s 204ms/step - loss: 1.4476 - accuracy: 0.8044 - val_loss: 1.5483 - val_accuracy: 0.6456\n",
            "Epoch 184/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4342 - accuracy: 0.8096\n",
            "LearningRate:0.057353\n",
            "97/97 [==============================] - 11s 109ms/step - loss: 1.4342 - accuracy: 0.8096 - val_loss: 1.6372 - val_accuracy: 0.5751\n",
            "Epoch 185/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4374 - accuracy: 0.8135\n",
            "LearningRate:0.056137\n",
            "97/97 [==============================] - 22s 225ms/step - loss: 1.4374 - accuracy: 0.8135 - val_loss: 1.6371 - val_accuracy: 0.5469\n",
            "Epoch 186/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4378 - accuracy: 0.8154\n",
            "LearningRate:0.054918\n",
            "97/97 [==============================] - 11s 110ms/step - loss: 1.4378 - accuracy: 0.8154 - val_loss: 1.7988 - val_accuracy: 0.4979\n",
            "Epoch 187/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4154 - accuracy: 0.8244\n",
            "LearningRate:0.053695\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.4154 - accuracy: 0.8244 - val_loss: 1.6769 - val_accuracy: 0.5187\n",
            "Epoch 188/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4186 - accuracy: 0.8196\n",
            "LearningRate:0.052471\n",
            "97/97 [==============================] - 17s 178ms/step - loss: 1.4186 - accuracy: 0.8196 - val_loss: 1.7848 - val_accuracy: 0.4896\n",
            "Epoch 189/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4157 - accuracy: 0.8235\n",
            "LearningRate:0.051245\n",
            "97/97 [==============================] - 17s 179ms/step - loss: 1.4157 - accuracy: 0.8235 - val_loss: 1.7905 - val_accuracy: 0.4871\n",
            "Epoch 190/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4098 - accuracy: 0.8338\n",
            "LearningRate:0.050018\n",
            "97/97 [==============================] - 15s 154ms/step - loss: 1.4098 - accuracy: 0.8338 - val_loss: 1.6314 - val_accuracy: 0.5834\n",
            "Epoch 191/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4097 - accuracy: 0.8299\n",
            "LearningRate:0.048791\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.4097 - accuracy: 0.8299 - val_loss: 1.6872 - val_accuracy: 0.5494\n",
            "Epoch 192/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3943 - accuracy: 0.8305\n",
            "LearningRate:0.047564\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.3943 - accuracy: 0.8305 - val_loss: 1.6646 - val_accuracy: 0.4846\n",
            "Epoch 193/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3874 - accuracy: 0.8280\n",
            "LearningRate:0.046340\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 1.3874 - accuracy: 0.8280 - val_loss: 1.4780 - val_accuracy: 0.6954\n",
            "Epoch 194/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3958 - accuracy: 0.8228\n",
            "LearningRate:0.045117\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.3958 - accuracy: 0.8228 - val_loss: 1.6170 - val_accuracy: 0.5593\n",
            "Epoch 195/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3902 - accuracy: 0.8351\n",
            "LearningRate:0.043898\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 1.3902 - accuracy: 0.8351 - val_loss: 1.6064 - val_accuracy: 0.6149\n",
            "Epoch 196/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3829 - accuracy: 0.8370\n",
            "LearningRate:0.042682\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 1.3829 - accuracy: 0.8370 - val_loss: 1.5100 - val_accuracy: 0.6515\n",
            "Epoch 197/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3630 - accuracy: 0.8454\n",
            "LearningRate:0.041470\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 1.3630 - accuracy: 0.8454 - val_loss: 1.6109 - val_accuracy: 0.5344\n",
            "Epoch 198/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3489 - accuracy: 0.8470\n",
            "LearningRate:0.040264\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.3489 - accuracy: 0.8470 - val_loss: 1.6205 - val_accuracy: 0.5635\n",
            "Epoch 199/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3564 - accuracy: 0.8512\n",
            "LearningRate:0.039063\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.3564 - accuracy: 0.8512 - val_loss: 1.7440 - val_accuracy: 0.4349\n",
            "Epoch 200/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.8483\n",
            "LearningRate:0.037869\n",
            "97/97 [==============================] - 15s 154ms/step - loss: 1.3657 - accuracy: 0.8483 - val_loss: 1.6714 - val_accuracy: 0.5369\n",
            "Epoch 201/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3496 - accuracy: 0.8479\n",
            "LearningRate:0.036683\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 1.3496 - accuracy: 0.8479 - val_loss: 1.5353 - val_accuracy: 0.6224\n",
            "Epoch 202/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3480 - accuracy: 0.8505\n",
            "LearningRate:0.035504\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.3480 - accuracy: 0.8505 - val_loss: 1.5736 - val_accuracy: 0.6166\n",
            "Epoch 203/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3239 - accuracy: 0.8595\n",
            "LearningRate:0.034334\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.3239 - accuracy: 0.8595 - val_loss: 1.3962 - val_accuracy: 0.6905\n",
            "Epoch 204/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3411 - accuracy: 0.8515\n",
            "LearningRate:0.033174\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.3411 - accuracy: 0.8515 - val_loss: 1.5287 - val_accuracy: 0.6124\n",
            "Epoch 205/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3221 - accuracy: 0.8605\n",
            "LearningRate:0.032024\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.3221 - accuracy: 0.8605 - val_loss: 1.5039 - val_accuracy: 0.6166\n",
            "Epoch 206/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3048 - accuracy: 0.8666\n",
            "LearningRate:0.030884\n",
            "97/97 [==============================] - 19s 193ms/step - loss: 1.3048 - accuracy: 0.8666 - val_loss: 1.4664 - val_accuracy: 0.6523\n",
            "Epoch 207/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2990 - accuracy: 0.8663\n",
            "LearningRate:0.029757\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 1.2990 - accuracy: 0.8663 - val_loss: 1.5692 - val_accuracy: 0.6149\n",
            "Epoch 208/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2822 - accuracy: 0.8776\n",
            "LearningRate:0.028641\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 1.2822 - accuracy: 0.8776 - val_loss: 1.6875 - val_accuracy: 0.6058\n",
            "Epoch 209/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3029 - accuracy: 0.8631\n",
            "LearningRate:0.027538\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.3029 - accuracy: 0.8631 - val_loss: 1.5336 - val_accuracy: 0.6174\n",
            "Epoch 210/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2862 - accuracy: 0.8744\n",
            "LearningRate:0.026449\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.2862 - accuracy: 0.8744 - val_loss: 1.5614 - val_accuracy: 0.5826\n",
            "Epoch 211/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2827 - accuracy: 0.8831\n",
            "LearningRate:0.025374\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.2827 - accuracy: 0.8831 - val_loss: 1.8705 - val_accuracy: 0.3759\n",
            "Epoch 212/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2758 - accuracy: 0.8737\n",
            "LearningRate:0.024313\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.2758 - accuracy: 0.8737 - val_loss: 1.4828 - val_accuracy: 0.5859\n",
            "Epoch 213/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2521 - accuracy: 0.8773\n",
            "LearningRate:0.023268\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 1.2521 - accuracy: 0.8773 - val_loss: 1.5207 - val_accuracy: 0.6448\n",
            "Epoch 214/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2549 - accuracy: 0.8834\n",
            "LearningRate:0.022240\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.2549 - accuracy: 0.8834 - val_loss: 1.6072 - val_accuracy: 0.5369\n",
            "Epoch 215/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2378 - accuracy: 0.8911\n",
            "LearningRate:0.021228\n",
            "97/97 [==============================] - 14s 144ms/step - loss: 1.2378 - accuracy: 0.8911 - val_loss: 1.4360 - val_accuracy: 0.6805\n",
            "Epoch 216/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2275 - accuracy: 0.8866\n",
            "LearningRate:0.020233\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.2275 - accuracy: 0.8866 - val_loss: 1.6429 - val_accuracy: 0.5394\n",
            "Epoch 217/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.8950\n",
            "LearningRate:0.019256\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.2295 - accuracy: 0.8950 - val_loss: 1.4169 - val_accuracy: 0.6614\n",
            "Epoch 218/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2373 - accuracy: 0.8863\n",
            "LearningRate:0.018298\n",
            "97/97 [==============================] - 14s 148ms/step - loss: 1.2373 - accuracy: 0.8863 - val_loss: 1.4933 - val_accuracy: 0.6340\n",
            "Epoch 219/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2158 - accuracy: 0.8895\n",
            "LearningRate:0.017359\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.2158 - accuracy: 0.8895 - val_loss: 1.5185 - val_accuracy: 0.6340\n",
            "Epoch 220/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2132 - accuracy: 0.8898\n",
            "LearningRate:0.016440\n",
            "97/97 [==============================] - 13s 139ms/step - loss: 1.2132 - accuracy: 0.8898 - val_loss: 1.5071 - val_accuracy: 0.6199\n",
            "Epoch 221/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2065 - accuracy: 0.9050\n",
            "LearningRate:0.015541\n",
            "97/97 [==============================] - 22s 227ms/step - loss: 1.2065 - accuracy: 0.9050 - val_loss: 1.4507 - val_accuracy: 0.7104\n",
            "Epoch 222/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1995 - accuracy: 0.8940\n",
            "LearningRate:0.014662\n",
            "97/97 [==============================] - 11s 110ms/step - loss: 1.1995 - accuracy: 0.8940 - val_loss: 1.3920 - val_accuracy: 0.6647\n",
            "Epoch 223/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1609 - accuracy: 0.9046\n",
            "LearningRate:0.013805\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 1.1609 - accuracy: 0.9046 - val_loss: 1.4381 - val_accuracy: 0.6573\n",
            "Epoch 224/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1744 - accuracy: 0.9053\n",
            "LearningRate:0.012970\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.1744 - accuracy: 0.9053 - val_loss: 1.3859 - val_accuracy: 0.7261\n",
            "Epoch 225/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1739 - accuracy: 0.9066\n",
            "LearningRate:0.012157\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.1739 - accuracy: 0.9066 - val_loss: 1.4570 - val_accuracy: 0.6896\n",
            "Epoch 226/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1574 - accuracy: 0.9124\n",
            "LearningRate:0.011366\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.1574 - accuracy: 0.9124 - val_loss: 1.5294 - val_accuracy: 0.5834\n",
            "Epoch 227/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1513 - accuracy: 0.9040\n",
            "LearningRate:0.010599\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.1513 - accuracy: 0.9040 - val_loss: 1.3975 - val_accuracy: 0.6714\n",
            "Epoch 228/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1309 - accuracy: 0.9217\n",
            "LearningRate:0.009856\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.1309 - accuracy: 0.9217 - val_loss: 1.3331 - val_accuracy: 0.6846\n",
            "Epoch 229/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1382 - accuracy: 0.9120\n",
            "LearningRate:0.009137\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.1382 - accuracy: 0.9120 - val_loss: 1.3195 - val_accuracy: 0.7510\n",
            "Epoch 230/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1158 - accuracy: 0.9178\n",
            "LearningRate:0.008443\n",
            "97/97 [==============================] - 14s 140ms/step - loss: 1.1158 - accuracy: 0.9178 - val_loss: 1.3436 - val_accuracy: 0.6979\n",
            "Epoch 231/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1160 - accuracy: 0.9230\n",
            "LearningRate:0.007773\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.1160 - accuracy: 0.9230 - val_loss: 1.2701 - val_accuracy: 0.7178\n",
            "Epoch 232/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1123 - accuracy: 0.9224\n",
            "LearningRate:0.007129\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.1123 - accuracy: 0.9224 - val_loss: 1.3506 - val_accuracy: 0.6954\n",
            "Epoch 233/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0840 - accuracy: 0.9285\n",
            "LearningRate:0.006511\n",
            "97/97 [==============================] - 19s 183ms/step - loss: 1.0840 - accuracy: 0.9285 - val_loss: 1.4102 - val_accuracy: 0.6763\n",
            "Epoch 234/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1088 - accuracy: 0.9204\n",
            "LearningRate:0.005919\n",
            "97/97 [==============================] - 14s 140ms/step - loss: 1.1088 - accuracy: 0.9204 - val_loss: 1.3081 - val_accuracy: 0.7195\n",
            "Epoch 235/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.9301\n",
            "LearningRate:0.005354\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.0958 - accuracy: 0.9301 - val_loss: 1.2375 - val_accuracy: 0.7726\n",
            "Epoch 236/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0780 - accuracy: 0.9336\n",
            "LearningRate:0.004815\n",
            "97/97 [==============================] - 21s 215ms/step - loss: 1.0780 - accuracy: 0.9336 - val_loss: 1.2367 - val_accuracy: 0.7577\n",
            "Epoch 237/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0740 - accuracy: 0.9272\n",
            "LearningRate:0.004304\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 1.0740 - accuracy: 0.9272 - val_loss: 1.2302 - val_accuracy: 0.7104\n",
            "Epoch 238/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0661 - accuracy: 0.9343\n",
            "LearningRate:0.003820\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.0661 - accuracy: 0.9343 - val_loss: 1.2288 - val_accuracy: 0.7519\n",
            "Epoch 239/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0632 - accuracy: 0.9233\n",
            "LearningRate:0.003365\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.0632 - accuracy: 0.9233 - val_loss: 1.2732 - val_accuracy: 0.7419\n",
            "Epoch 240/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0551 - accuracy: 0.9430\n",
            "LearningRate:0.002937\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.0551 - accuracy: 0.9430 - val_loss: 1.2813 - val_accuracy: 0.7303\n",
            "Epoch 241/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0583 - accuracy: 0.9301\n",
            "LearningRate:0.002537\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.0583 - accuracy: 0.9301 - val_loss: 1.2265 - val_accuracy: 0.7759\n",
            "Epoch 242/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0478 - accuracy: 0.9275\n",
            "LearningRate:0.002166\n",
            "97/97 [==============================] - 12s 126ms/step - loss: 1.0478 - accuracy: 0.9275 - val_loss: 1.2309 - val_accuracy: 0.7195\n",
            "Epoch 243/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0370 - accuracy: 0.9372\n",
            "LearningRate:0.001824\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.0370 - accuracy: 0.9372 - val_loss: 1.2160 - val_accuracy: 0.7817\n",
            "Epoch 244/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0287 - accuracy: 0.9427\n",
            "LearningRate:0.001511\n",
            "97/97 [==============================] - 18s 181ms/step - loss: 1.0287 - accuracy: 0.9427 - val_loss: 1.1773 - val_accuracy: 0.8008\n",
            "Epoch 245/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0205 - accuracy: 0.9369\n",
            "LearningRate:0.001228\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.0205 - accuracy: 0.9369 - val_loss: 1.2140 - val_accuracy: 0.7900\n",
            "Epoch 246/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0272 - accuracy: 0.9378\n",
            "LearningRate:0.000973\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.0272 - accuracy: 0.9378 - val_loss: 1.1858 - val_accuracy: 0.7801\n",
            "Epoch 247/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0140 - accuracy: 0.9352\n",
            "LearningRate:0.000748\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 1.0140 - accuracy: 0.9352 - val_loss: 1.1961 - val_accuracy: 0.7710\n",
            "Epoch 248/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0140 - accuracy: 0.9433\n",
            "LearningRate:0.000553\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.0140 - accuracy: 0.9433 - val_loss: 1.1781 - val_accuracy: 0.7909\n",
            "Epoch 249/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0064 - accuracy: 0.9410\n",
            "LearningRate:0.000388\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.0064 - accuracy: 0.9410 - val_loss: 1.1725 - val_accuracy: 0.7892\n",
            "Epoch 250/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0283 - accuracy: 0.9436\n",
            "LearningRate:0.000252\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.0283 - accuracy: 0.9436 - val_loss: 1.1729 - val_accuracy: 0.7867\n",
            "Epoch 251/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0230 - accuracy: 0.9314\n",
            "LearningRate:0.000146\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.0230 - accuracy: 0.9314 - val_loss: 1.1575 - val_accuracy: 0.7934\n",
            "Epoch 252/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9937 - accuracy: 0.9459\n",
            "LearningRate:0.000071\n",
            "97/97 [==============================] - 19s 196ms/step - loss: 0.9937 - accuracy: 0.9459 - val_loss: 1.1596 - val_accuracy: 0.7909\n",
            "Epoch 253/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0324 - accuracy: 0.9340\n",
            "LearningRate:0.000025\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 1.0324 - accuracy: 0.9340 - val_loss: 1.1597 - val_accuracy: 0.7900\n",
            "Epoch 254/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.9417\n",
            "LearningRate:0.000010\n",
            "97/97 [==============================] - 19s 196ms/step - loss: 1.0086 - accuracy: 0.9417 - val_loss: 1.1572 - val_accuracy: 0.7934\n",
            "Epoch 255/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.8821 - accuracy: 0.5010\n",
            "LearningRate:0.099996\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 1.8821 - accuracy: 0.5010 - val_loss: 22.3205 - val_accuracy: 0.1751\n",
            "Epoch 256/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.7628 - accuracy: 0.5718\n",
            "LearningRate:0.099985\n",
            "97/97 [==============================] - 21s 215ms/step - loss: 1.7628 - accuracy: 0.5718 - val_loss: 1.8828 - val_accuracy: 0.3527\n",
            "Epoch 257/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.7033 - accuracy: 0.6131\n",
            "LearningRate:0.099966\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 1.7033 - accuracy: 0.6131 - val_loss: 1.8930 - val_accuracy: 0.4207\n",
            "Epoch 258/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6851 - accuracy: 0.6034\n",
            "LearningRate:0.099940\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.6851 - accuracy: 0.6034 - val_loss: 1.8427 - val_accuracy: 0.3876\n",
            "Epoch 259/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6733 - accuracy: 0.6347\n",
            "LearningRate:0.099906\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.6733 - accuracy: 0.6347 - val_loss: 1.7251 - val_accuracy: 0.4589\n",
            "Epoch 260/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6706 - accuracy: 0.6366\n",
            "LearningRate:0.099865\n",
            "97/97 [==============================] - 20s 207ms/step - loss: 1.6706 - accuracy: 0.6366 - val_loss: 1.7136 - val_accuracy: 0.4946\n",
            "Epoch 261/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6449 - accuracy: 0.6579\n",
            "LearningRate:0.099816\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.6449 - accuracy: 0.6579 - val_loss: 1.8844 - val_accuracy: 0.4415\n",
            "Epoch 262/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6446 - accuracy: 0.6546\n",
            "LearningRate:0.099760\n",
            "97/97 [==============================] - 13s 133ms/step - loss: 1.6446 - accuracy: 0.6546 - val_loss: 1.8698 - val_accuracy: 0.4191\n",
            "Epoch 263/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6422 - accuracy: 0.6537\n",
            "LearningRate:0.099696\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.6422 - accuracy: 0.6537 - val_loss: 1.7813 - val_accuracy: 0.4730\n",
            "Epoch 264/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6200 - accuracy: 0.6595\n",
            "LearningRate:0.099625\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.6200 - accuracy: 0.6595 - val_loss: 1.6288 - val_accuracy: 0.4888\n",
            "Epoch 265/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6292 - accuracy: 0.6598\n",
            "LearningRate:0.099546\n",
            "97/97 [==============================] - 13s 134ms/step - loss: 1.6292 - accuracy: 0.6598 - val_loss: 1.7146 - val_accuracy: 0.4963\n",
            "Epoch 266/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6224 - accuracy: 0.6807\n",
            "LearningRate:0.099460\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.6224 - accuracy: 0.6807 - val_loss: 1.7035 - val_accuracy: 0.4880\n",
            "Epoch 267/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6524 - accuracy: 0.6508\n",
            "LearningRate:0.099366\n",
            "97/97 [==============================] - 18s 189ms/step - loss: 1.6524 - accuracy: 0.6508 - val_loss: 1.9642 - val_accuracy: 0.3859\n",
            "Epoch 268/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6115 - accuracy: 0.6836\n",
            "LearningRate:0.099265\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.6115 - accuracy: 0.6836 - val_loss: 1.7489 - val_accuracy: 0.4614\n",
            "Epoch 269/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6041 - accuracy: 0.6753\n",
            "LearningRate:0.099157\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.6041 - accuracy: 0.6753 - val_loss: 1.8005 - val_accuracy: 0.4456\n",
            "Epoch 270/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6027 - accuracy: 0.6968\n",
            "LearningRate:0.099041\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.6027 - accuracy: 0.6968 - val_loss: 1.6767 - val_accuracy: 0.5577\n",
            "Epoch 271/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5894 - accuracy: 0.6881\n",
            "LearningRate:0.098917\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 1.5894 - accuracy: 0.6881 - val_loss: 1.6815 - val_accuracy: 0.4913\n",
            "Epoch 272/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6015 - accuracy: 0.7052\n",
            "LearningRate:0.098787\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.6015 - accuracy: 0.7052 - val_loss: 1.5064 - val_accuracy: 0.6100\n",
            "Epoch 273/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6039 - accuracy: 0.6856\n",
            "LearningRate:0.098649\n",
            "97/97 [==============================] - 17s 178ms/step - loss: 1.6039 - accuracy: 0.6856 - val_loss: 1.6424 - val_accuracy: 0.5651\n",
            "Epoch 274/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 0.6975\n",
            "LearningRate:0.098503\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.5890 - accuracy: 0.6975 - val_loss: 2.0382 - val_accuracy: 0.3693\n",
            "Epoch 275/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6053 - accuracy: 0.6933\n",
            "LearningRate:0.098351\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.6053 - accuracy: 0.6933 - val_loss: 1.7902 - val_accuracy: 0.4332\n",
            "Epoch 276/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6082 - accuracy: 0.6939\n",
            "LearningRate:0.098191\n",
            "97/97 [==============================] - 20s 209ms/step - loss: 1.6082 - accuracy: 0.6939 - val_loss: 1.8063 - val_accuracy: 0.4581\n",
            "Epoch 277/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6040 - accuracy: 0.7014\n",
            "LearningRate:0.098023\n",
            "97/97 [==============================] - 11s 119ms/step - loss: 1.6040 - accuracy: 0.7014 - val_loss: 1.8572 - val_accuracy: 0.4340\n",
            "Epoch 278/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6212 - accuracy: 0.6975\n",
            "LearningRate:0.097849\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.6212 - accuracy: 0.6975 - val_loss: 2.0444 - val_accuracy: 0.3784\n",
            "Epoch 279/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5935 - accuracy: 0.7120\n",
            "LearningRate:0.097667\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 1.5935 - accuracy: 0.7120 - val_loss: 1.6073 - val_accuracy: 0.5378\n",
            "Epoch 280/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5916 - accuracy: 0.7113\n",
            "LearningRate:0.097479\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.5916 - accuracy: 0.7113 - val_loss: 1.7019 - val_accuracy: 0.4747\n",
            "Epoch 281/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5827 - accuracy: 0.7188\n",
            "LearningRate:0.097283\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.5827 - accuracy: 0.7188 - val_loss: 1.8047 - val_accuracy: 0.5129\n",
            "Epoch 282/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6177 - accuracy: 0.7017\n",
            "LearningRate:0.097080\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.6177 - accuracy: 0.7017 - val_loss: 1.6798 - val_accuracy: 0.5320\n",
            "Epoch 283/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5925 - accuracy: 0.7168\n",
            "LearningRate:0.096869\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.5925 - accuracy: 0.7168 - val_loss: 1.9295 - val_accuracy: 0.3610\n",
            "Epoch 284/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 0.7184\n",
            "LearningRate:0.096652\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 1.5871 - accuracy: 0.7184 - val_loss: 1.9775 - val_accuracy: 0.3444\n",
            "Epoch 285/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5870 - accuracy: 0.7300\n",
            "LearningRate:0.096428\n",
            "97/97 [==============================] - 19s 196ms/step - loss: 1.5870 - accuracy: 0.7300 - val_loss: 1.9060 - val_accuracy: 0.4183\n",
            "Epoch 286/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5999 - accuracy: 0.7188\n",
            "LearningRate:0.096197\n",
            "97/97 [==============================] - 13s 135ms/step - loss: 1.5999 - accuracy: 0.7188 - val_loss: 1.6692 - val_accuracy: 0.5427\n",
            "Epoch 287/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5903 - accuracy: 0.7123\n",
            "LearningRate:0.095959\n",
            "97/97 [==============================] - 17s 179ms/step - loss: 1.5903 - accuracy: 0.7123 - val_loss: 1.6973 - val_accuracy: 0.5054\n",
            "Epoch 288/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5857 - accuracy: 0.7316\n",
            "LearningRate:0.095713\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 1.5857 - accuracy: 0.7316 - val_loss: 1.7904 - val_accuracy: 0.4822\n",
            "Epoch 289/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5851 - accuracy: 0.7255\n",
            "LearningRate:0.095461\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.5851 - accuracy: 0.7255 - val_loss: 1.8302 - val_accuracy: 0.3967\n",
            "Epoch 290/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5625 - accuracy: 0.7442\n",
            "LearningRate:0.095203\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.5625 - accuracy: 0.7442 - val_loss: 1.8699 - val_accuracy: 0.3876\n",
            "Epoch 291/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.6019 - accuracy: 0.7216\n",
            "LearningRate:0.094937\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.6019 - accuracy: 0.7216 - val_loss: 1.6471 - val_accuracy: 0.5693\n",
            "Epoch 292/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5684 - accuracy: 0.7316\n",
            "LearningRate:0.094665\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.5684 - accuracy: 0.7316 - val_loss: 1.5989 - val_accuracy: 0.5593\n",
            "Epoch 293/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5855 - accuracy: 0.7233\n",
            "LearningRate:0.094385\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.5855 - accuracy: 0.7233 - val_loss: 1.8934 - val_accuracy: 0.3975\n",
            "Epoch 294/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5858 - accuracy: 0.7320\n",
            "LearningRate:0.094100\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.5858 - accuracy: 0.7320 - val_loss: 1.7267 - val_accuracy: 0.4863\n",
            "Epoch 295/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.7426\n",
            "LearningRate:0.093807\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.5650 - accuracy: 0.7426 - val_loss: 1.7006 - val_accuracy: 0.4697\n",
            "Epoch 296/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5674 - accuracy: 0.7416\n",
            "LearningRate:0.093508\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 1.5674 - accuracy: 0.7416 - val_loss: 1.5964 - val_accuracy: 0.6050\n",
            "Epoch 297/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5709 - accuracy: 0.7358\n",
            "LearningRate:0.093203\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.5709 - accuracy: 0.7358 - val_loss: 2.0980 - val_accuracy: 0.2822\n",
            "Epoch 298/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5755 - accuracy: 0.7300\n",
            "LearningRate:0.092890\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.5755 - accuracy: 0.7300 - val_loss: 1.7687 - val_accuracy: 0.5104\n",
            "Epoch 299/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5638 - accuracy: 0.7436\n",
            "LearningRate:0.092572\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.5638 - accuracy: 0.7436 - val_loss: 1.7206 - val_accuracy: 0.5079\n",
            "Epoch 300/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5689 - accuracy: 0.7394\n",
            "LearningRate:0.092247\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.5689 - accuracy: 0.7394 - val_loss: 1.8882 - val_accuracy: 0.4075\n",
            "Epoch 301/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 0.7291\n",
            "LearningRate:0.091915\n",
            "97/97 [==============================] - 21s 223ms/step - loss: 1.5966 - accuracy: 0.7291 - val_loss: 1.6280 - val_accuracy: 0.5353\n",
            "Epoch 302/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5792 - accuracy: 0.7378\n",
            "LearningRate:0.091578\n",
            "97/97 [==============================] - 11s 110ms/step - loss: 1.5792 - accuracy: 0.7378 - val_loss: 1.9446 - val_accuracy: 0.4282\n",
            "Epoch 303/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5803 - accuracy: 0.7474\n",
            "LearningRate:0.091234\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.5803 - accuracy: 0.7474 - val_loss: 1.9577 - val_accuracy: 0.4066\n",
            "Epoch 304/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5717 - accuracy: 0.7432\n",
            "LearningRate:0.090884\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.5717 - accuracy: 0.7432 - val_loss: 1.7803 - val_accuracy: 0.4606\n",
            "Epoch 305/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5543 - accuracy: 0.7474\n",
            "LearningRate:0.090528\n",
            "97/97 [==============================] - 21s 215ms/step - loss: 1.5543 - accuracy: 0.7474 - val_loss: 1.7876 - val_accuracy: 0.4763\n",
            "Epoch 306/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5353 - accuracy: 0.7564\n",
            "LearningRate:0.090165\n",
            "97/97 [==============================] - 11s 119ms/step - loss: 1.5353 - accuracy: 0.7564 - val_loss: 1.6666 - val_accuracy: 0.5527\n",
            "Epoch 307/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5510 - accuracy: 0.7465\n",
            "LearningRate:0.089797\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.5510 - accuracy: 0.7465 - val_loss: 1.9186 - val_accuracy: 0.4573\n",
            "Epoch 308/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5837 - accuracy: 0.7365\n",
            "LearningRate:0.089422\n",
            "97/97 [==============================] - 19s 193ms/step - loss: 1.5837 - accuracy: 0.7365 - val_loss: 1.7630 - val_accuracy: 0.4075\n",
            "Epoch 309/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5735 - accuracy: 0.7468\n",
            "LearningRate:0.089042\n",
            "97/97 [==============================] - 13s 130ms/step - loss: 1.5735 - accuracy: 0.7468 - val_loss: 1.8214 - val_accuracy: 0.4523\n",
            "Epoch 310/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5508 - accuracy: 0.7555\n",
            "LearningRate:0.088656\n",
            "97/97 [==============================] - 23s 240ms/step - loss: 1.5508 - accuracy: 0.7555 - val_loss: 1.7983 - val_accuracy: 0.4672\n",
            "Epoch 311/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 0.7687\n",
            "LearningRate:0.088264\n",
            "97/97 [==============================] - 11s 111ms/step - loss: 1.5341 - accuracy: 0.7687 - val_loss: 2.2923 - val_accuracy: 0.2481\n",
            "Epoch 312/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5442 - accuracy: 0.7568\n",
            "LearningRate:0.087866\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.5442 - accuracy: 0.7568 - val_loss: 2.0733 - val_accuracy: 0.2946\n",
            "Epoch 313/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5477 - accuracy: 0.7613\n",
            "LearningRate:0.087462\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.5477 - accuracy: 0.7613 - val_loss: 1.8598 - val_accuracy: 0.4199\n",
            "Epoch 314/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5346 - accuracy: 0.7729\n",
            "LearningRate:0.087053\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 1.5346 - accuracy: 0.7729 - val_loss: 1.8128 - val_accuracy: 0.5253\n",
            "Epoch 315/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5487 - accuracy: 0.7555\n",
            "LearningRate:0.086638\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.5487 - accuracy: 0.7555 - val_loss: 1.9441 - val_accuracy: 0.4083\n",
            "Epoch 316/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5329 - accuracy: 0.7648\n",
            "LearningRate:0.086218\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.5329 - accuracy: 0.7648 - val_loss: 1.7577 - val_accuracy: 0.4830\n",
            "Epoch 317/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5382 - accuracy: 0.7713\n",
            "LearningRate:0.085792\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.5382 - accuracy: 0.7713 - val_loss: 1.6367 - val_accuracy: 0.4979\n",
            "Epoch 318/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5400 - accuracy: 0.7635\n",
            "LearningRate:0.085361\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 1.5400 - accuracy: 0.7635 - val_loss: 1.6860 - val_accuracy: 0.5336\n",
            "Epoch 319/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.7713\n",
            "LearningRate:0.084925\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.5236 - accuracy: 0.7713 - val_loss: 1.6844 - val_accuracy: 0.5162\n",
            "Epoch 320/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 0.7713\n",
            "LearningRate:0.084483\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.5264 - accuracy: 0.7713 - val_loss: 1.9774 - val_accuracy: 0.3784\n",
            "Epoch 321/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5295 - accuracy: 0.7600\n",
            "LearningRate:0.084036\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.5295 - accuracy: 0.7600 - val_loss: 1.6461 - val_accuracy: 0.5544\n",
            "Epoch 322/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 0.7803\n",
            "LearningRate:0.083584\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.5299 - accuracy: 0.7803 - val_loss: 1.7358 - val_accuracy: 0.5685\n",
            "Epoch 323/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5447 - accuracy: 0.7629\n",
            "LearningRate:0.083127\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.5447 - accuracy: 0.7629 - val_loss: 1.7993 - val_accuracy: 0.4523\n",
            "Epoch 324/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5374 - accuracy: 0.7671\n",
            "LearningRate:0.082665\n",
            "97/97 [==============================] - 13s 130ms/step - loss: 1.5374 - accuracy: 0.7671 - val_loss: 1.6548 - val_accuracy: 0.5693\n",
            "Epoch 325/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5375 - accuracy: 0.7600\n",
            "LearningRate:0.082198\n",
            "97/97 [==============================] - 20s 205ms/step - loss: 1.5375 - accuracy: 0.7600 - val_loss: 1.6934 - val_accuracy: 0.5311\n",
            "Epoch 326/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5007 - accuracy: 0.7980\n",
            "LearningRate:0.081726\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.5007 - accuracy: 0.7980 - val_loss: 1.7908 - val_accuracy: 0.4440\n",
            "Epoch 327/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5533 - accuracy: 0.7668\n",
            "LearningRate:0.081250\n",
            "97/97 [==============================] - 12s 128ms/step - loss: 1.5533 - accuracy: 0.7668 - val_loss: 1.9660 - val_accuracy: 0.3867\n",
            "Epoch 328/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 0.7745\n",
            "LearningRate:0.080768\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.5293 - accuracy: 0.7745 - val_loss: 1.6861 - val_accuracy: 0.5286\n",
            "Epoch 329/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5169 - accuracy: 0.7703\n",
            "LearningRate:0.080283\n",
            "97/97 [==============================] - 14s 143ms/step - loss: 1.5169 - accuracy: 0.7703 - val_loss: 2.0855 - val_accuracy: 0.3154\n",
            "Epoch 330/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5149 - accuracy: 0.7838\n",
            "LearningRate:0.079792\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.5149 - accuracy: 0.7838 - val_loss: 1.6254 - val_accuracy: 0.5436\n",
            "Epoch 331/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5187 - accuracy: 0.7626\n",
            "LearningRate:0.079297\n",
            "97/97 [==============================] - 18s 191ms/step - loss: 1.5187 - accuracy: 0.7626 - val_loss: 1.9415 - val_accuracy: 0.3817\n",
            "Epoch 332/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5312 - accuracy: 0.7709\n",
            "LearningRate:0.078798\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 1.5312 - accuracy: 0.7709 - val_loss: 1.6944 - val_accuracy: 0.5793\n",
            "Epoch 333/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5139 - accuracy: 0.7800\n",
            "LearningRate:0.078294\n",
            "97/97 [==============================] - 13s 133ms/step - loss: 1.5139 - accuracy: 0.7800 - val_loss: 1.8721 - val_accuracy: 0.3867\n",
            "Epoch 334/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5001 - accuracy: 0.7903\n",
            "LearningRate:0.077786\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.5001 - accuracy: 0.7903 - val_loss: 1.6448 - val_accuracy: 0.5369\n",
            "Epoch 335/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5092 - accuracy: 0.7761\n",
            "LearningRate:0.077274\n",
            "97/97 [==============================] - 20s 205ms/step - loss: 1.5092 - accuracy: 0.7761 - val_loss: 1.6479 - val_accuracy: 0.6100\n",
            "Epoch 336/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4908 - accuracy: 0.7967\n",
            "LearningRate:0.076758\n",
            "97/97 [==============================] - 14s 141ms/step - loss: 1.4908 - accuracy: 0.7967 - val_loss: 1.6223 - val_accuracy: 0.5892\n",
            "Epoch 337/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5212 - accuracy: 0.7777\n",
            "LearningRate:0.076237\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.5212 - accuracy: 0.7777 - val_loss: 1.6225 - val_accuracy: 0.5685\n",
            "Epoch 338/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5049 - accuracy: 0.7887\n",
            "LearningRate:0.075713\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.5049 - accuracy: 0.7887 - val_loss: 1.8934 - val_accuracy: 0.4133\n",
            "Epoch 339/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5201 - accuracy: 0.7909\n",
            "LearningRate:0.075185\n",
            "97/97 [==============================] - 19s 202ms/step - loss: 1.5201 - accuracy: 0.7909 - val_loss: 2.2081 - val_accuracy: 0.2523\n",
            "Epoch 340/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5140 - accuracy: 0.7903\n",
            "LearningRate:0.074653\n",
            "97/97 [==============================] - 11s 109ms/step - loss: 1.5140 - accuracy: 0.7903 - val_loss: 1.7352 - val_accuracy: 0.5502\n",
            "Epoch 341/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.8025\n",
            "LearningRate:0.074117\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.4749 - accuracy: 0.8025 - val_loss: 1.7107 - val_accuracy: 0.4963\n",
            "Epoch 342/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4796 - accuracy: 0.7951\n",
            "LearningRate:0.073578\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.4796 - accuracy: 0.7951 - val_loss: 1.7070 - val_accuracy: 0.5502\n",
            "Epoch 343/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5050 - accuracy: 0.7806\n",
            "LearningRate:0.073035\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.5050 - accuracy: 0.7806 - val_loss: 1.6566 - val_accuracy: 0.5793\n",
            "Epoch 344/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4973 - accuracy: 0.7887\n",
            "LearningRate:0.072489\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.4973 - accuracy: 0.7887 - val_loss: 1.5902 - val_accuracy: 0.6066\n",
            "Epoch 345/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4853 - accuracy: 0.7925\n",
            "LearningRate:0.071939\n",
            "97/97 [==============================] - 15s 150ms/step - loss: 1.4853 - accuracy: 0.7925 - val_loss: 1.6664 - val_accuracy: 0.5129\n",
            "Epoch 346/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5013 - accuracy: 0.7903\n",
            "LearningRate:0.071386\n",
            "97/97 [==============================] - 19s 193ms/step - loss: 1.5013 - accuracy: 0.7903 - val_loss: 1.8265 - val_accuracy: 0.4822\n",
            "Epoch 347/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.5056 - accuracy: 0.7816\n",
            "LearningRate:0.070830\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.5056 - accuracy: 0.7816 - val_loss: 1.4807 - val_accuracy: 0.6108\n",
            "Epoch 348/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4769 - accuracy: 0.8032\n",
            "LearningRate:0.070271\n",
            "97/97 [==============================] - 18s 191ms/step - loss: 1.4769 - accuracy: 0.8032 - val_loss: 1.7142 - val_accuracy: 0.4863\n",
            "Epoch 349/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4748 - accuracy: 0.8141\n",
            "LearningRate:0.069708\n",
            "97/97 [==============================] - 11s 111ms/step - loss: 1.4748 - accuracy: 0.8141 - val_loss: 1.8638 - val_accuracy: 0.4133\n",
            "Epoch 350/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4963 - accuracy: 0.7945\n",
            "LearningRate:0.069143\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.4963 - accuracy: 0.7945 - val_loss: 1.8917 - val_accuracy: 0.4083\n",
            "Epoch 351/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.8067\n",
            "LearningRate:0.068575\n",
            "97/97 [==============================] - 17s 179ms/step - loss: 1.4749 - accuracy: 0.8067 - val_loss: 1.9703 - val_accuracy: 0.4415\n",
            "Epoch 352/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4779 - accuracy: 0.7935\n",
            "LearningRate:0.068004\n",
            "97/97 [==============================] - 14s 144ms/step - loss: 1.4779 - accuracy: 0.7935 - val_loss: 1.6832 - val_accuracy: 0.5461\n",
            "Epoch 353/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4625 - accuracy: 0.8028\n",
            "LearningRate:0.067430\n",
            "97/97 [==============================] - 15s 154ms/step - loss: 1.4625 - accuracy: 0.8028 - val_loss: 1.6756 - val_accuracy: 0.5278\n",
            "Epoch 354/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4503 - accuracy: 0.8180\n",
            "LearningRate:0.066854\n",
            "97/97 [==============================] - 20s 208ms/step - loss: 1.4503 - accuracy: 0.8180 - val_loss: 1.6574 - val_accuracy: 0.6050\n",
            "Epoch 355/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4442 - accuracy: 0.8138\n",
            "LearningRate:0.066275\n",
            "97/97 [==============================] - 14s 143ms/step - loss: 1.4442 - accuracy: 0.8138 - val_loss: 2.1561 - val_accuracy: 0.3461\n",
            "Epoch 356/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4710 - accuracy: 0.8032\n",
            "LearningRate:0.065694\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 1.4710 - accuracy: 0.8032 - val_loss: 1.5671 - val_accuracy: 0.6091\n",
            "Epoch 357/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4753 - accuracy: 0.8019\n",
            "LearningRate:0.065110\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.4753 - accuracy: 0.8019 - val_loss: 1.7667 - val_accuracy: 0.5012\n",
            "Epoch 358/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4571 - accuracy: 0.8109\n",
            "LearningRate:0.064524\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.4571 - accuracy: 0.8109 - val_loss: 1.5766 - val_accuracy: 0.6589\n",
            "Epoch 359/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4488 - accuracy: 0.8115\n",
            "LearningRate:0.063936\n",
            "97/97 [==============================] - 15s 152ms/step - loss: 1.4488 - accuracy: 0.8115 - val_loss: 1.6752 - val_accuracy: 0.5378\n",
            "Epoch 360/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.8151\n",
            "LearningRate:0.063345\n",
            "97/97 [==============================] - 19s 196ms/step - loss: 1.4627 - accuracy: 0.8151 - val_loss: 1.7247 - val_accuracy: 0.5228\n",
            "Epoch 361/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4607 - accuracy: 0.8141\n",
            "LearningRate:0.062753\n",
            "97/97 [==============================] - 13s 133ms/step - loss: 1.4607 - accuracy: 0.8141 - val_loss: 1.5435 - val_accuracy: 0.6307\n",
            "Epoch 362/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4497 - accuracy: 0.8225\n",
            "LearningRate:0.062159\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.4497 - accuracy: 0.8225 - val_loss: 1.5967 - val_accuracy: 0.6124\n",
            "Epoch 363/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 0.8157\n",
            "LearningRate:0.061563\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.4423 - accuracy: 0.8157 - val_loss: 1.8178 - val_accuracy: 0.4241\n",
            "Epoch 364/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4495 - accuracy: 0.8061\n",
            "LearningRate:0.060965\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.4495 - accuracy: 0.8061 - val_loss: 1.6678 - val_accuracy: 0.5942\n",
            "Epoch 365/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4312 - accuracy: 0.8196\n",
            "LearningRate:0.060366\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.4312 - accuracy: 0.8196 - val_loss: 1.5821 - val_accuracy: 0.6490\n",
            "Epoch 366/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4273 - accuracy: 0.8276\n",
            "LearningRate:0.059765\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.4273 - accuracy: 0.8276 - val_loss: 1.6855 - val_accuracy: 0.5228\n",
            "Epoch 367/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4391 - accuracy: 0.8164\n",
            "LearningRate:0.059162\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.4391 - accuracy: 0.8164 - val_loss: 1.6608 - val_accuracy: 0.5278\n",
            "Epoch 368/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4455 - accuracy: 0.7996\n",
            "LearningRate:0.058558\n",
            "97/97 [==============================] - 18s 189ms/step - loss: 1.4455 - accuracy: 0.7996 - val_loss: 1.6878 - val_accuracy: 0.5104\n",
            "Epoch 369/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4450 - accuracy: 0.8051\n",
            "LearningRate:0.057953\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 1.4450 - accuracy: 0.8051 - val_loss: 1.5757 - val_accuracy: 0.5743\n",
            "Epoch 370/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4402 - accuracy: 0.8289\n",
            "LearningRate:0.057347\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 1.4402 - accuracy: 0.8289 - val_loss: 1.6268 - val_accuracy: 0.6108\n",
            "Epoch 371/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4258 - accuracy: 0.8135\n",
            "LearningRate:0.056740\n",
            "97/97 [==============================] - 19s 196ms/step - loss: 1.4258 - accuracy: 0.8135 - val_loss: 1.8668 - val_accuracy: 0.3668\n",
            "Epoch 372/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4261 - accuracy: 0.8344\n",
            "LearningRate:0.056131\n",
            "97/97 [==============================] - 13s 136ms/step - loss: 1.4261 - accuracy: 0.8344 - val_loss: 1.6595 - val_accuracy: 0.5627\n",
            "Epoch 373/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4412 - accuracy: 0.8202\n",
            "LearningRate:0.055522\n",
            "97/97 [==============================] - 19s 199ms/step - loss: 1.4412 - accuracy: 0.8202 - val_loss: 1.8667 - val_accuracy: 0.3983\n",
            "Epoch 374/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4299 - accuracy: 0.8170\n",
            "LearningRate:0.054912\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.4299 - accuracy: 0.8170 - val_loss: 1.4434 - val_accuracy: 0.6722\n",
            "Epoch 375/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4141 - accuracy: 0.8296\n",
            "LearningRate:0.054301\n",
            "97/97 [==============================] - 17s 180ms/step - loss: 1.4141 - accuracy: 0.8296 - val_loss: 1.9240 - val_accuracy: 0.3826\n",
            "Epoch 376/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4253 - accuracy: 0.8238\n",
            "LearningRate:0.053689\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.4253 - accuracy: 0.8238 - val_loss: 1.6162 - val_accuracy: 0.6108\n",
            "Epoch 377/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4097 - accuracy: 0.8241\n",
            "LearningRate:0.053077\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.4097 - accuracy: 0.8241 - val_loss: 1.5876 - val_accuracy: 0.5378\n",
            "Epoch 378/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4054 - accuracy: 0.8322\n",
            "LearningRate:0.052464\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.4054 - accuracy: 0.8322 - val_loss: 1.6224 - val_accuracy: 0.5983\n",
            "Epoch 379/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3973 - accuracy: 0.8363\n",
            "LearningRate:0.051851\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.3973 - accuracy: 0.8363 - val_loss: 1.6137 - val_accuracy: 0.6008\n",
            "Epoch 380/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4149 - accuracy: 0.8357\n",
            "LearningRate:0.051238\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.4149 - accuracy: 0.8357 - val_loss: 1.6448 - val_accuracy: 0.5295\n",
            "Epoch 381/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4021 - accuracy: 0.8289\n",
            "LearningRate:0.050625\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 1.4021 - accuracy: 0.8289 - val_loss: 1.9646 - val_accuracy: 0.3037\n",
            "Epoch 382/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4051 - accuracy: 0.8386\n",
            "LearningRate:0.050011\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 1.4051 - accuracy: 0.8386 - val_loss: 1.6492 - val_accuracy: 0.6000\n",
            "Epoch 383/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4131 - accuracy: 0.8177\n",
            "LearningRate:0.049398\n",
            "97/97 [==============================] - 19s 197ms/step - loss: 1.4131 - accuracy: 0.8177 - val_loss: 1.6321 - val_accuracy: 0.5344\n",
            "Epoch 384/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3909 - accuracy: 0.8376\n",
            "LearningRate:0.048784\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.3909 - accuracy: 0.8376 - val_loss: 1.4686 - val_accuracy: 0.6564\n",
            "Epoch 385/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3842 - accuracy: 0.8415\n",
            "LearningRate:0.048171\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 1.3842 - accuracy: 0.8415 - val_loss: 1.6911 - val_accuracy: 0.5469\n",
            "Epoch 386/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3694 - accuracy: 0.8492\n",
            "LearningRate:0.047558\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.3694 - accuracy: 0.8492 - val_loss: 1.8759 - val_accuracy: 0.3934\n",
            "Epoch 387/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3982 - accuracy: 0.8328\n",
            "LearningRate:0.046946\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.3982 - accuracy: 0.8328 - val_loss: 1.6610 - val_accuracy: 0.5469\n",
            "Epoch 388/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3749 - accuracy: 0.8380\n",
            "LearningRate:0.046333\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 1.3749 - accuracy: 0.8380 - val_loss: 1.4963 - val_accuracy: 0.6921\n",
            "Epoch 389/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3817 - accuracy: 0.8412\n",
            "LearningRate:0.045722\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.3817 - accuracy: 0.8412 - val_loss: 1.5163 - val_accuracy: 0.6838\n",
            "Epoch 390/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3680 - accuracy: 0.8537\n",
            "LearningRate:0.045111\n",
            "97/97 [==============================] - 17s 176ms/step - loss: 1.3680 - accuracy: 0.8537 - val_loss: 1.6954 - val_accuracy: 0.4938\n",
            "Epoch 391/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3774 - accuracy: 0.8550\n",
            "LearningRate:0.044501\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.3774 - accuracy: 0.8550 - val_loss: 1.6809 - val_accuracy: 0.5303\n",
            "Epoch 392/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3697 - accuracy: 0.8409\n",
            "LearningRate:0.043891\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.3697 - accuracy: 0.8409 - val_loss: 1.7064 - val_accuracy: 0.5170\n",
            "Epoch 393/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3902 - accuracy: 0.8299\n",
            "LearningRate:0.043283\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.3902 - accuracy: 0.8299 - val_loss: 1.6970 - val_accuracy: 0.4863\n",
            "Epoch 394/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3614 - accuracy: 0.8586\n",
            "LearningRate:0.042675\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.3614 - accuracy: 0.8586 - val_loss: 1.6891 - val_accuracy: 0.5353\n",
            "Epoch 395/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3620 - accuracy: 0.8537\n",
            "LearningRate:0.042069\n",
            "97/97 [==============================] - 17s 174ms/step - loss: 1.3620 - accuracy: 0.8537 - val_loss: 1.9038 - val_accuracy: 0.3062\n",
            "Epoch 396/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3593 - accuracy: 0.8595\n",
            "LearningRate:0.041464\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.3593 - accuracy: 0.8595 - val_loss: 1.7152 - val_accuracy: 0.4448\n",
            "Epoch 397/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3432 - accuracy: 0.8563\n",
            "LearningRate:0.040860\n",
            "97/97 [==============================] - 19s 194ms/step - loss: 1.3432 - accuracy: 0.8563 - val_loss: 1.6030 - val_accuracy: 0.5568\n",
            "Epoch 398/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3289 - accuracy: 0.8573\n",
            "LearningRate:0.040258\n",
            "97/97 [==============================] - 13s 137ms/step - loss: 1.3289 - accuracy: 0.8573 - val_loss: 1.7029 - val_accuracy: 0.5104\n",
            "Epoch 399/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3505 - accuracy: 0.8573\n",
            "LearningRate:0.039657\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.3505 - accuracy: 0.8573 - val_loss: 1.6403 - val_accuracy: 0.5145\n",
            "Epoch 400/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.8679\n",
            "LearningRate:0.039057\n",
            "97/97 [==============================] - 16s 163ms/step - loss: 1.3284 - accuracy: 0.8679 - val_loss: 1.4740 - val_accuracy: 0.6274\n",
            "Epoch 401/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3463 - accuracy: 0.8615\n",
            "LearningRate:0.038459\n",
            "97/97 [==============================] - 24s 245ms/step - loss: 1.3463 - accuracy: 0.8615 - val_loss: 1.6114 - val_accuracy: 0.5519\n",
            "Epoch 402/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3489 - accuracy: 0.8457\n",
            "LearningRate:0.037863\n",
            "97/97 [==============================] - 11s 110ms/step - loss: 1.3489 - accuracy: 0.8457 - val_loss: 1.8179 - val_accuracy: 0.4158\n",
            "Epoch 403/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3304 - accuracy: 0.8682\n",
            "LearningRate:0.037269\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 1.3304 - accuracy: 0.8682 - val_loss: 1.5480 - val_accuracy: 0.6041\n",
            "Epoch 404/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3256 - accuracy: 0.8663\n",
            "LearningRate:0.036677\n",
            "97/97 [==============================] - 18s 189ms/step - loss: 1.3256 - accuracy: 0.8663 - val_loss: 1.6676 - val_accuracy: 0.5734\n",
            "Epoch 405/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3102 - accuracy: 0.8727\n",
            "LearningRate:0.036086\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.3102 - accuracy: 0.8727 - val_loss: 1.7380 - val_accuracy: 0.5228\n",
            "Epoch 406/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3254 - accuracy: 0.8663\n",
            "LearningRate:0.035498\n",
            "97/97 [==============================] - 17s 179ms/step - loss: 1.3254 - accuracy: 0.8663 - val_loss: 1.5827 - val_accuracy: 0.5577\n",
            "Epoch 407/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3111 - accuracy: 0.8798\n",
            "LearningRate:0.034912\n",
            "97/97 [==============================] - 14s 149ms/step - loss: 1.3111 - accuracy: 0.8798 - val_loss: 1.7029 - val_accuracy: 0.4846\n",
            "Epoch 408/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3105 - accuracy: 0.8640\n",
            "LearningRate:0.034328\n",
            "97/97 [==============================] - 20s 181ms/step - loss: 1.3105 - accuracy: 0.8640 - val_loss: 1.5279 - val_accuracy: 0.6224\n",
            "Epoch 409/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3030 - accuracy: 0.8731\n",
            "LearningRate:0.033747\n",
            "97/97 [==============================] - 14s 148ms/step - loss: 1.3030 - accuracy: 0.8731 - val_loss: 1.5378 - val_accuracy: 0.6083\n",
            "Epoch 410/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3028 - accuracy: 0.8708\n",
            "LearningRate:0.033168\n",
            "97/97 [==============================] - 19s 194ms/step - loss: 1.3028 - accuracy: 0.8708 - val_loss: 1.6953 - val_accuracy: 0.5178\n",
            "Epoch 411/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3034 - accuracy: 0.8727\n",
            "LearningRate:0.032592\n",
            "97/97 [==============================] - 13s 137ms/step - loss: 1.3034 - accuracy: 0.8727 - val_loss: 1.5582 - val_accuracy: 0.6249\n",
            "Epoch 412/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3032 - accuracy: 0.8650\n",
            "LearningRate:0.032018\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 1.3032 - accuracy: 0.8650 - val_loss: 1.3893 - val_accuracy: 0.7411\n",
            "Epoch 413/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.3083 - accuracy: 0.8686\n",
            "LearningRate:0.031447\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3083 - accuracy: 0.8686 - val_loss: 1.7819 - val_accuracy: 0.5378\n",
            "Epoch 414/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2714 - accuracy: 0.8892\n",
            "LearningRate:0.030879\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.2714 - accuracy: 0.8892 - val_loss: 1.5739 - val_accuracy: 0.6382\n",
            "Epoch 415/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2902 - accuracy: 0.8811\n",
            "LearningRate:0.030313\n",
            "97/97 [==============================] - 14s 141ms/step - loss: 1.2902 - accuracy: 0.8811 - val_loss: 1.6127 - val_accuracy: 0.5660\n",
            "Epoch 416/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2965 - accuracy: 0.8731\n",
            "LearningRate:0.029751\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.2965 - accuracy: 0.8731 - val_loss: 1.7170 - val_accuracy: 0.5195\n",
            "Epoch 417/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2706 - accuracy: 0.8776\n",
            "LearningRate:0.029191\n",
            "97/97 [==============================] - 17s 177ms/step - loss: 1.2706 - accuracy: 0.8776 - val_loss: 1.5588 - val_accuracy: 0.5353\n",
            "Epoch 418/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2646 - accuracy: 0.8750\n",
            "LearningRate:0.028635\n",
            "97/97 [==============================] - 21s 216ms/step - loss: 1.2646 - accuracy: 0.8750 - val_loss: 1.4621 - val_accuracy: 0.6415\n",
            "Epoch 419/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2624 - accuracy: 0.8843\n",
            "LearningRate:0.028082\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 1.2624 - accuracy: 0.8843 - val_loss: 1.6516 - val_accuracy: 0.5203\n",
            "Epoch 420/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2653 - accuracy: 0.8782\n",
            "LearningRate:0.027532\n",
            "97/97 [==============================] - 12s 124ms/step - loss: 1.2653 - accuracy: 0.8782 - val_loss: 1.6486 - val_accuracy: 0.5768\n",
            "Epoch 421/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2648 - accuracy: 0.8776\n",
            "LearningRate:0.026986\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.2648 - accuracy: 0.8776 - val_loss: 1.5178 - val_accuracy: 0.6149\n",
            "Epoch 422/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2610 - accuracy: 0.8814\n",
            "LearningRate:0.026443\n",
            "97/97 [==============================] - 21s 217ms/step - loss: 1.2610 - accuracy: 0.8814 - val_loss: 1.4869 - val_accuracy: 0.6382\n",
            "Epoch 423/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2344 - accuracy: 0.9040\n",
            "LearningRate:0.025904\n",
            "97/97 [==============================] - 11s 112ms/step - loss: 1.2344 - accuracy: 0.9040 - val_loss: 1.8799 - val_accuracy: 0.3535\n",
            "Epoch 424/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.8892\n",
            "LearningRate:0.025368\n",
            "97/97 [==============================] - 20s 207ms/step - loss: 1.2301 - accuracy: 0.8892 - val_loss: 1.4598 - val_accuracy: 0.6689\n",
            "Epoch 425/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2462 - accuracy: 0.8860\n",
            "LearningRate:0.024836\n",
            "97/97 [==============================] - 12s 127ms/step - loss: 1.2462 - accuracy: 0.8860 - val_loss: 1.5792 - val_accuracy: 0.5660\n",
            "Epoch 426/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2437 - accuracy: 0.8892\n",
            "LearningRate:0.024308\n",
            "97/97 [==============================] - 20s 207ms/step - loss: 1.2437 - accuracy: 0.8892 - val_loss: 1.5695 - val_accuracy: 0.6008\n",
            "Epoch 427/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2275 - accuracy: 0.8956\n",
            "LearningRate:0.023784\n",
            "97/97 [==============================] - 12s 125ms/step - loss: 1.2275 - accuracy: 0.8956 - val_loss: 1.5256 - val_accuracy: 0.5992\n",
            "Epoch 428/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2423 - accuracy: 0.8818\n",
            "LearningRate:0.023263\n",
            "97/97 [==============================] - 18s 190ms/step - loss: 1.2423 - accuracy: 0.8818 - val_loss: 1.4418 - val_accuracy: 0.6938\n",
            "Epoch 429/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2251 - accuracy: 0.8911\n",
            "LearningRate:0.022747\n",
            "97/97 [==============================] - 14s 150ms/step - loss: 1.2251 - accuracy: 0.8911 - val_loss: 1.4841 - val_accuracy: 0.5801\n",
            "Epoch 430/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2292 - accuracy: 0.8921\n",
            "LearningRate:0.022235\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.2292 - accuracy: 0.8921 - val_loss: 1.6546 - val_accuracy: 0.5552\n",
            "Epoch 431/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2144 - accuracy: 0.8988\n",
            "LearningRate:0.021726\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.2144 - accuracy: 0.8988 - val_loss: 1.5443 - val_accuracy: 0.5909\n",
            "Epoch 432/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2079 - accuracy: 0.8992\n",
            "LearningRate:0.021223\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.2079 - accuracy: 0.8992 - val_loss: 1.5234 - val_accuracy: 0.5817\n",
            "Epoch 433/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2221 - accuracy: 0.8850\n",
            "LearningRate:0.020723\n",
            "97/97 [==============================] - 22s 232ms/step - loss: 1.2221 - accuracy: 0.8850 - val_loss: 1.6492 - val_accuracy: 0.5286\n",
            "Epoch 434/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1931 - accuracy: 0.9005\n",
            "LearningRate:0.020228\n",
            "97/97 [==============================] - 11s 110ms/step - loss: 1.1931 - accuracy: 0.9005 - val_loss: 1.4662 - val_accuracy: 0.7104\n",
            "Epoch 435/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2172 - accuracy: 0.8889\n",
            "LearningRate:0.019738\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.2172 - accuracy: 0.8889 - val_loss: 1.4946 - val_accuracy: 0.5975\n",
            "Epoch 436/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1900 - accuracy: 0.9021\n",
            "LearningRate:0.019251\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.1900 - accuracy: 0.9021 - val_loss: 1.4953 - val_accuracy: 0.5942\n",
            "Epoch 437/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1946 - accuracy: 0.9056\n",
            "LearningRate:0.018770\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.1946 - accuracy: 0.9056 - val_loss: 1.4475 - val_accuracy: 0.7054\n",
            "Epoch 438/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1915 - accuracy: 0.9008\n",
            "LearningRate:0.018293\n",
            "97/97 [==============================] - 15s 154ms/step - loss: 1.1915 - accuracy: 0.9008 - val_loss: 1.4814 - val_accuracy: 0.6373\n",
            "Epoch 439/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1856 - accuracy: 0.9098\n",
            "LearningRate:0.017821\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.1856 - accuracy: 0.9098 - val_loss: 1.3720 - val_accuracy: 0.6805\n",
            "Epoch 440/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1842 - accuracy: 0.9137\n",
            "LearningRate:0.017354\n",
            "97/97 [==============================] - 20s 208ms/step - loss: 1.1842 - accuracy: 0.9137 - val_loss: 1.4161 - val_accuracy: 0.6722\n",
            "Epoch 441/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1706 - accuracy: 0.9034\n",
            "LearningRate:0.016892\n",
            "97/97 [==============================] - 17s 181ms/step - loss: 1.1706 - accuracy: 0.9034 - val_loss: 1.5369 - val_accuracy: 0.6689\n",
            "Epoch 442/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1872 - accuracy: 0.9062\n",
            "LearningRate:0.016435\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 1.1872 - accuracy: 0.9062 - val_loss: 1.4050 - val_accuracy: 0.6407\n",
            "Epoch 443/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1789 - accuracy: 0.9104\n",
            "LearningRate:0.015983\n",
            "97/97 [==============================] - 19s 201ms/step - loss: 1.1789 - accuracy: 0.9104 - val_loss: 1.5033 - val_accuracy: 0.6216\n",
            "Epoch 444/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.9220\n",
            "LearningRate:0.015536\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 1.1696 - accuracy: 0.9220 - val_loss: 1.3764 - val_accuracy: 0.7012\n",
            "Epoch 445/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1499 - accuracy: 0.9075\n",
            "LearningRate:0.015094\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 1.1499 - accuracy: 0.9075 - val_loss: 1.4410 - val_accuracy: 0.6423\n",
            "Epoch 446/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1676 - accuracy: 0.8995\n",
            "LearningRate:0.014658\n",
            "97/97 [==============================] - 21s 213ms/step - loss: 1.1676 - accuracy: 0.8995 - val_loss: 1.4694 - val_accuracy: 0.6315\n",
            "Epoch 447/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1436 - accuracy: 0.9133\n",
            "LearningRate:0.014226\n",
            "97/97 [==============================] - 11s 109ms/step - loss: 1.1436 - accuracy: 0.9133 - val_loss: 1.3453 - val_accuracy: 0.7311\n",
            "Epoch 448/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1340 - accuracy: 0.9214\n",
            "LearningRate:0.013801\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 1.1340 - accuracy: 0.9214 - val_loss: 1.4893 - val_accuracy: 0.6216\n",
            "Epoch 449/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1377 - accuracy: 0.9169\n",
            "LearningRate:0.013380\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.1377 - accuracy: 0.9169 - val_loss: 1.4746 - val_accuracy: 0.6556\n",
            "Epoch 450/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1189 - accuracy: 0.9130\n",
            "LearningRate:0.012965\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.1189 - accuracy: 0.9130 - val_loss: 1.3440 - val_accuracy: 0.7145\n",
            "Epoch 451/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1254 - accuracy: 0.9282\n",
            "LearningRate:0.012556\n",
            "97/97 [==============================] - 22s 225ms/step - loss: 1.1254 - accuracy: 0.9282 - val_loss: 1.5549 - val_accuracy: 0.5900\n",
            "Epoch 452/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1182 - accuracy: 0.9236\n",
            "LearningRate:0.012152\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.1182 - accuracy: 0.9236 - val_loss: 1.3294 - val_accuracy: 0.7178\n",
            "Epoch 453/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1290 - accuracy: 0.9137\n",
            "LearningRate:0.011755\n",
            "97/97 [==============================] - 14s 140ms/step - loss: 1.1290 - accuracy: 0.9137 - val_loss: 1.3426 - val_accuracy: 0.6913\n",
            "Epoch 454/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1073 - accuracy: 0.9185\n",
            "LearningRate:0.011362\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.1073 - accuracy: 0.9185 - val_loss: 1.3709 - val_accuracy: 0.6705\n",
            "Epoch 455/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1027 - accuracy: 0.9301\n",
            "LearningRate:0.010976\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.1027 - accuracy: 0.9301 - val_loss: 1.3521 - val_accuracy: 0.7386\n",
            "Epoch 456/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1086 - accuracy: 0.9227\n",
            "LearningRate:0.010596\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.1086 - accuracy: 0.9227 - val_loss: 1.3863 - val_accuracy: 0.6838\n",
            "Epoch 457/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.1133 - accuracy: 0.9272\n",
            "LearningRate:0.010221\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 1.1133 - accuracy: 0.9272 - val_loss: 1.4497 - val_accuracy: 0.6357\n",
            "Epoch 458/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0886 - accuracy: 0.9249\n",
            "LearningRate:0.009852\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.0886 - accuracy: 0.9249 - val_loss: 1.3213 - val_accuracy: 0.6913\n",
            "Epoch 459/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0988 - accuracy: 0.9217\n",
            "LearningRate:0.009490\n",
            "97/97 [==============================] - 13s 136ms/step - loss: 1.0988 - accuracy: 0.9217 - val_loss: 1.4307 - val_accuracy: 0.6290\n",
            "Epoch 460/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0845 - accuracy: 0.9378\n",
            "LearningRate:0.009133\n",
            "97/97 [==============================] - 19s 195ms/step - loss: 1.0845 - accuracy: 0.9378 - val_loss: 1.3411 - val_accuracy: 0.6863\n",
            "Epoch 461/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0727 - accuracy: 0.9269\n",
            "LearningRate:0.008783\n",
            "97/97 [==============================] - 14s 141ms/step - loss: 1.0727 - accuracy: 0.9269 - val_loss: 1.3226 - val_accuracy: 0.7560\n",
            "Epoch 462/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.9156\n",
            "LearningRate:0.008439\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 1.0864 - accuracy: 0.9156 - val_loss: 1.2976 - val_accuracy: 0.7261\n",
            "Epoch 463/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0699 - accuracy: 0.9340\n",
            "LearningRate:0.008101\n",
            "97/97 [==============================] - 16s 169ms/step - loss: 1.0699 - accuracy: 0.9340 - val_loss: 1.3689 - val_accuracy: 0.6780\n",
            "Epoch 464/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0567 - accuracy: 0.9330\n",
            "LearningRate:0.007770\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.0567 - accuracy: 0.9330 - val_loss: 1.3496 - val_accuracy: 0.7104\n",
            "Epoch 465/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.9323\n",
            "LearningRate:0.007445\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 1.0626 - accuracy: 0.9323 - val_loss: 1.4145 - val_accuracy: 0.6788\n",
            "Epoch 466/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0541 - accuracy: 0.9359\n",
            "LearningRate:0.007126\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.0541 - accuracy: 0.9359 - val_loss: 1.2429 - val_accuracy: 0.7618\n",
            "Epoch 467/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0420 - accuracy: 0.9391\n",
            "LearningRate:0.006814\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 1.0420 - accuracy: 0.9391 - val_loss: 1.3299 - val_accuracy: 0.7303\n",
            "Epoch 468/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0393 - accuracy: 0.9401\n",
            "LearningRate:0.006508\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 1.0393 - accuracy: 0.9401 - val_loss: 1.3072 - val_accuracy: 0.7477\n",
            "Epoch 469/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0532 - accuracy: 0.9362\n",
            "LearningRate:0.006209\n",
            "97/97 [==============================] - 20s 204ms/step - loss: 1.0532 - accuracy: 0.9362 - val_loss: 1.3929 - val_accuracy: 0.6805\n",
            "Epoch 470/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0484 - accuracy: 0.9285\n",
            "LearningRate:0.005916\n",
            "97/97 [==============================] - 13s 138ms/step - loss: 1.0484 - accuracy: 0.9285 - val_loss: 1.3808 - val_accuracy: 0.7071\n",
            "Epoch 471/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0439 - accuracy: 0.9398\n",
            "LearningRate:0.005630\n",
            "97/97 [==============================] - 16s 171ms/step - loss: 1.0439 - accuracy: 0.9398 - val_loss: 1.3609 - val_accuracy: 0.7195\n",
            "Epoch 472/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0312 - accuracy: 0.9427\n",
            "LearningRate:0.005351\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 1.0312 - accuracy: 0.9427 - val_loss: 1.3319 - val_accuracy: 0.7104\n",
            "Epoch 473/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.9414\n",
            "LearningRate:0.005079\n",
            "97/97 [==============================] - 20s 208ms/step - loss: 1.0143 - accuracy: 0.9414 - val_loss: 1.2782 - val_accuracy: 0.7220\n",
            "Epoch 474/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0071 - accuracy: 0.9436\n",
            "LearningRate:0.004813\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 1.0071 - accuracy: 0.9436 - val_loss: 1.2341 - val_accuracy: 0.7419\n",
            "Epoch 475/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.9436\n",
            "LearningRate:0.004554\n",
            "97/97 [==============================] - 18s 182ms/step - loss: 1.0228 - accuracy: 0.9436 - val_loss: 1.3239 - val_accuracy: 0.6548\n",
            "Epoch 476/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.9385\n",
            "LearningRate:0.004302\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.0228 - accuracy: 0.9385 - val_loss: 1.2718 - val_accuracy: 0.7519\n",
            "Epoch 477/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.9410\n",
            "LearningRate:0.004056\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 1.0044 - accuracy: 0.9410 - val_loss: 1.2693 - val_accuracy: 0.7303\n",
            "Epoch 478/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.9452\n",
            "LearningRate:0.003818\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 1.0043 - accuracy: 0.9452 - val_loss: 1.2966 - val_accuracy: 0.7320\n",
            "Epoch 479/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9991 - accuracy: 0.9407\n",
            "LearningRate:0.003587\n",
            "97/97 [==============================] - 20s 206ms/step - loss: 0.9991 - accuracy: 0.9407 - val_loss: 1.2699 - val_accuracy: 0.7560\n",
            "Epoch 480/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9982 - accuracy: 0.9459\n",
            "LearningRate:0.003362\n",
            "97/97 [==============================] - 11s 114ms/step - loss: 0.9982 - accuracy: 0.9459 - val_loss: 1.3511 - val_accuracy: 0.6888\n",
            "Epoch 481/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0034 - accuracy: 0.9436\n",
            "LearningRate:0.003145\n",
            "97/97 [==============================] - 17s 178ms/step - loss: 1.0034 - accuracy: 0.9436 - val_loss: 1.2464 - val_accuracy: 0.7801\n",
            "Epoch 482/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.9472\n",
            "LearningRate:0.002935\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 0.9917 - accuracy: 0.9472 - val_loss: 1.3199 - val_accuracy: 0.7162\n",
            "Epoch 483/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9979 - accuracy: 0.9414\n",
            "LearningRate:0.002731\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 0.9979 - accuracy: 0.9414 - val_loss: 1.2397 - val_accuracy: 0.7651\n",
            "Epoch 484/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.9398\n",
            "LearningRate:0.002535\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 1.0036 - accuracy: 0.9398 - val_loss: 1.2167 - val_accuracy: 0.7643\n",
            "Epoch 485/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.9456\n",
            "LearningRate:0.002346\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 0.9759 - accuracy: 0.9456 - val_loss: 1.2880 - val_accuracy: 0.7311\n",
            "Epoch 486/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.9443\n",
            "LearningRate:0.002165\n",
            "97/97 [==============================] - 19s 197ms/step - loss: 0.9926 - accuracy: 0.9443 - val_loss: 1.1923 - val_accuracy: 0.7884\n",
            "Epoch 487/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.9459\n",
            "LearningRate:0.001990\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 0.9900 - accuracy: 0.9459 - val_loss: 1.2442 - val_accuracy: 0.7710\n",
            "Epoch 488/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9601 - accuracy: 0.9446\n",
            "LearningRate:0.001823\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 0.9601 - accuracy: 0.9446 - val_loss: 1.2242 - val_accuracy: 0.7668\n",
            "Epoch 489/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.9452\n",
            "LearningRate:0.001663\n",
            "97/97 [==============================] - 20s 204ms/step - loss: 0.9780 - accuracy: 0.9452 - val_loss: 1.2147 - val_accuracy: 0.7527\n",
            "Epoch 490/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9739 - accuracy: 0.9433\n",
            "LearningRate:0.001510\n",
            "97/97 [==============================] - 13s 136ms/step - loss: 0.9739 - accuracy: 0.9433 - val_loss: 1.1982 - val_accuracy: 0.7992\n",
            "Epoch 491/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9800 - accuracy: 0.9420\n",
            "LearningRate:0.001364\n",
            "97/97 [==============================] - 15s 160ms/step - loss: 0.9800 - accuracy: 0.9420 - val_loss: 1.2134 - val_accuracy: 0.7817\n",
            "Epoch 492/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9575 - accuracy: 0.9555\n",
            "LearningRate:0.001226\n",
            "97/97 [==============================] - 19s 196ms/step - loss: 0.9575 - accuracy: 0.9555 - val_loss: 1.2122 - val_accuracy: 0.7710\n",
            "Epoch 493/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9620 - accuracy: 0.9520\n",
            "LearningRate:0.001095\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 0.9620 - accuracy: 0.9520 - val_loss: 1.1925 - val_accuracy: 0.7842\n",
            "Epoch 494/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9668 - accuracy: 0.9507\n",
            "LearningRate:0.000972\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 0.9668 - accuracy: 0.9507 - val_loss: 1.2002 - val_accuracy: 0.7809\n",
            "Epoch 495/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9596 - accuracy: 0.9536\n",
            "LearningRate:0.000856\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 0.9596 - accuracy: 0.9536 - val_loss: 1.2311 - val_accuracy: 0.7602\n",
            "Epoch 496/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9603 - accuracy: 0.9481\n",
            "LearningRate:0.000747\n",
            "97/97 [==============================] - 19s 202ms/step - loss: 0.9603 - accuracy: 0.9481 - val_loss: 1.2027 - val_accuracy: 0.7884\n",
            "Epoch 497/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9476 - accuracy: 0.9488\n",
            "LearningRate:0.000646\n",
            "97/97 [==============================] - 12s 125ms/step - loss: 0.9476 - accuracy: 0.9488 - val_loss: 1.1860 - val_accuracy: 0.7967\n",
            "Epoch 498/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.9526\n",
            "LearningRate:0.000552\n",
            "97/97 [==============================] - 18s 183ms/step - loss: 0.9339 - accuracy: 0.9526 - val_loss: 1.2017 - val_accuracy: 0.7867\n",
            "Epoch 499/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9482 - accuracy: 0.9543\n",
            "LearningRate:0.000466\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 0.9482 - accuracy: 0.9543 - val_loss: 1.1789 - val_accuracy: 0.7867\n",
            "Epoch 500/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9544 - accuracy: 0.9497\n",
            "LearningRate:0.000387\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 0.9544 - accuracy: 0.9497 - val_loss: 1.1848 - val_accuracy: 0.7909\n",
            "Epoch 501/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9611 - accuracy: 0.9485\n",
            "LearningRate:0.000315\n",
            "97/97 [==============================] - 16s 168ms/step - loss: 0.9611 - accuracy: 0.9485 - val_loss: 1.1626 - val_accuracy: 0.8050\n",
            "Epoch 502/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9517 - accuracy: 0.9446\n",
            "LearningRate:0.000251\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 0.9517 - accuracy: 0.9446 - val_loss: 1.1774 - val_accuracy: 0.7992\n",
            "Epoch 503/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9409 - accuracy: 0.9501\n",
            "LearningRate:0.000195\n",
            "97/97 [==============================] - 17s 178ms/step - loss: 0.9409 - accuracy: 0.9501 - val_loss: 1.1762 - val_accuracy: 0.8033\n",
            "Epoch 504/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9381 - accuracy: 0.9568\n",
            "LearningRate:0.000146\n",
            "97/97 [==============================] - 15s 159ms/step - loss: 0.9381 - accuracy: 0.9568 - val_loss: 1.1681 - val_accuracy: 0.7975\n",
            "Epoch 505/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9413 - accuracy: 0.9536\n",
            "LearningRate:0.000104\n",
            "97/97 [==============================] - 17s 175ms/step - loss: 0.9413 - accuracy: 0.9536 - val_loss: 1.1684 - val_accuracy: 0.7967\n",
            "Epoch 506/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9336 - accuracy: 0.9559\n",
            "LearningRate:0.000071\n",
            "97/97 [==============================] - 15s 152ms/step - loss: 0.9336 - accuracy: 0.9559 - val_loss: 1.1783 - val_accuracy: 0.7909\n",
            "Epoch 507/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9441 - accuracy: 0.9472\n",
            "LearningRate:0.000044\n",
            "97/97 [==============================] - 16s 164ms/step - loss: 0.9441 - accuracy: 0.9472 - val_loss: 1.1697 - val_accuracy: 0.7967\n",
            "Epoch 508/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9446 - accuracy: 0.9510\n",
            "LearningRate:0.000025\n",
            "97/97 [==============================] - 16s 166ms/step - loss: 0.9446 - accuracy: 0.9510 - val_loss: 1.1659 - val_accuracy: 0.7959\n",
            "Epoch 509/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9398 - accuracy: 0.9504\n",
            "LearningRate:0.000014\n",
            "97/97 [==============================] - 19s 192ms/step - loss: 0.9398 - accuracy: 0.9504 - val_loss: 1.1680 - val_accuracy: 0.7942\n",
            "Epoch 510/510\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.9343 - accuracy: 0.9485\n",
            "LearningRate:0.000010\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 0.9343 - accuracy: 0.9485 - val_loss: 1.1691 - val_accuracy: 0.7959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WhUKoN4cQOTT"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/' + WhichTask + '_Task_development_1.keras')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/' + WhichTask + '_Task_development_1.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LqBQQWN3Msz4",
        "outputId": "c8a45d4b-e150-4726-f2da-b5bcda8ae964"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64857bc0-0ada-44a1-824e-02f80603349a\", \"1a_Task_development_1.keras\", 26437406)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import scipy.io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "from DCASE_plots import plot_confusion_matrix\n",
        "\n",
        "import librosa\n",
        "import soundfile as sound\n",
        "import keras\n",
        "import tensorflow\n",
        "print(\"Librosa version = \",librosa.__version__)\n",
        "print(\"Pysoundfile version = \",sound.__version__)\n",
        "print(\"keras version = \",keras.__version__)\n",
        "print(\"tensorflow version = \",tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjMLpIAbNDsv",
        "outputId": "8a0facea-efdf-4c33-9887-d62741af927b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librosa version =  0.10.2\n",
            "Pysoundfile version =  0.12.1\n",
            "keras version =  2.15.0\n",
            "tensorflow version =  2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1a dev validation set\n",
        "File = '/content/drive/MyDrive/dataset_root/TAU-urban-acoustic-scenes-2019-development_(Subtask A)/evaluation_setup/fold1_evaluate.csv'\n",
        "sr = 48000\n",
        "SampleDuration = 10\n",
        "NumFreqBins = 128\n",
        "NumFFTPoints = 2048\n",
        "HopLength = int(NumFFTPoints/2)\n",
        "NumTimeBins = int(np.ceil(SampleDuration*sr/HopLength))"
      ],
      "metadata": {
        "id": "zQdB7vbRNWdA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load filenames and labels\n",
        "dev_test_df = pd.read_csv(File,sep=',', encoding='ASCII')\n",
        "wavpaths = dev_test_df['filename'].tolist()\n",
        "ClassNames = np.unique(dev_test_df['scene_label'])\n",
        "y_val_labels =  dev_test_df['scene_label'].astype('category').cat.codes.values\n",
        "\n",
        "#swap codes for 2 and 1 to match the DCASE ordering of classes\n",
        "a1=np.where(y_val_labels==2)\n",
        "a2=np.where(y_val_labels==3)\n",
        "y_val_labels.setflags(write=1)\n",
        "y_val_labels[a1] = 3\n",
        "y_val_labels[a2] = 2"
      ],
      "metadata": {
        "id": "gD0ZlwqzNyYm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load wav files and get log-mel spectrograms, deltas, and delta-deltas\n",
        "def deltas(X_in):\n",
        "    X_out = (X_in[:,:,2:,:]-X_in[:,:,:-2,:])/10.0\n",
        "    X_out = X_out[:,:,1:-1,:]+(X_in[:,:,4:,:]-X_in[:,:,:-4,:])/5.0\n",
        "    return X_out\n",
        "\n",
        "LM_val = np.zeros((len(wavpaths),NumFreqBins,NumTimeBins,2),'float32')\n",
        "for i in range(len(wavpaths)):\n",
        "    stereo,fs = sound.read(ThisPath + wavpaths[i],stop=SampleDuration*sr)\n",
        "    for channel in range(2):\n",
        "        LM_val[i, :, :, channel] = librosa.feature.melspectrogram(y=stereo[:, channel],\n",
        "                                                          sr=sr,\n",
        "                                                          n_fft=NumFFTPoints,\n",
        "                                                          hop_length=HopLength,\n",
        "                                                          n_mels=NumFreqBins,\n",
        "                                                          fmin=0.0,\n",
        "                                                          fmax=sr/2,\n",
        "                                                          htk=True,\n",
        "                                                          norm=None)\n",
        "\n",
        "\n",
        "LM_val=np.log(LM_val)\n",
        "LM_deltas_val = deltas(LM_val)\n",
        "LM_deltas_deltas_val = deltas(LM_deltas_val)\n",
        "LM_val = np.concatenate((LM_val[:,:,4:-4,:],LM_deltas_val[:,:,2:-2,:],LM_deltas_deltas_val),axis=-1)"
      ],
      "metadata": {
        "id": "k0i9nD_LOMjX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on the validation data (LM_val)\n",
        "y_pred_val = np.argmax(model.predict(LM_val), axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YojVk9RGPkFP",
        "outputId": "40fe3e35-0c62-4bf6-a958-a1ddbdd56333"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 1s 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get metrics\n",
        "Overall_accuracy = np.sum(y_pred_val==y_val_labels)/LM_val.shape[0]\n",
        "print(\"overall accuracy: \", Overall_accuracy)\n",
        "\n",
        "plot_confusion_matrix(y_val_labels, y_pred_val, ClassNames,normalize=True,title=None)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val_labels,y_pred_val)\n",
        "conf_mat_norm_recall = conf_matrix.astype('float32')/conf_matrix.sum(axis=1)[:,np.newaxis]\n",
        "conf_mat_norm_precision = conf_matrix.astype('float32')/conf_matrix.sum(axis=0)[:,np.newaxis]\n",
        "recall_by_class = np.diagonal(conf_mat_norm_recall)\n",
        "precision_by_class = np.diagonal(conf_mat_norm_precision)\n",
        "mean_recall = np.mean(recall_by_class)\n",
        "mean_precision = np.mean(precision_by_class)\n",
        "\n",
        "print(\"per-class accuracy (recall): \",recall_by_class)\n",
        "print(\"per-class precision: \",precision_by_class)\n",
        "print(\"mean per-class recall: \",mean_recall)\n",
        "print(\"mean per-class precision: \",mean_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NYaCxy1JQARV",
        "outputId": "378464b4-a50f-4a39-bfd5-883e29e52199"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overall accuracy:  0.6514522821576764\n",
            "Normalized confusion matrix\n",
            "per-class accuracy (recall):  [0.84347826 0.75892857 0.0075188  0.13592233 1.         0.24074074\n",
            " 0.95321637 0.65048544 0.98550725 0.77192982]\n",
            "per-class precision:  [0.87387387 0.83333333 0.0106383  0.0979021  0.83076923 0.66666667\n",
            " 0.95321637 0.57758621 0.74725275 0.75213675]\n",
            "mean per-class recall:  0.634772758222887\n",
            "mean per-class precision:  0.63433755809726\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ha9uT5rcQYxW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}